<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><title>SUSE Edge Documentation | Troubleshooting Directed-network provisioning</title><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes"/><link rel="stylesheet" type="text/css" href="static/css/style.css"/>
<link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"/><link rel="schema.DCTERMS" href="http://purl.org/dc/terms/"/>
<meta name="title" content="Troubleshooting Directed-network provisioning"/>
<meta name="description" content="Directed-network provisioning scenarios involve using Metal3 and CAPI elements to provision the Downstream cluster. It also includes EIB to create an…"/>
<meta name="book-title" content="SUSE Edge Documentation"/>
<meta name="chapter-title" content="Chapter 50. Troubleshooting Directed-network provisioning"/>
<meta name="tracker-url" content="https://github.com/suse-edge/suse-edge.github.io/issues/new"/>
<meta name="tracker-type" content="gh"/>
<meta name="publisher" content="SUSE"/><meta property="og:title" content="Troubleshooting Directed-network provisioning"/>
<meta property="og:description" content="Directed-network provisioning scenarios involve using Metal…"/>
<meta property="og:type" content="article"/>
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Troubleshooting Directed-network provisioning"/>
<meta name="twitter:description" content="Directed-network provisioning scenarios involve using Metal…"/>
<script type="application/ld+json">{
    "@context": "http://schema.org",
    "@type": ["TechArticle"],
    "image": "https://www.suse.com/assets/img/suse-white-logo-green.svg",
    
     "isPartOf": {
      "@type": "CreativeWorkSeries",
      "name": "Products &amp; Solutions"
    },
    

    "headline": "Troubleshooting Directed-network provisioning",
  
    "description": "Troubleshooting Directed-network provisioning",
      
    "author": [
      {
        "@type": "Corporation",
        "name": "SUSE Product &amp; Solution Documentation Team",
        "url": "https://www.suse.com/assets/img/suse-white-logo-green.svg"
      }
    ],
      

    "about": [
      
    ],
  
    "sameAs": [
          "https://www.facebook.com/SUSEWorldwide/about",
          "https://www.youtube.com/channel/UCHTfqIzPKz4f_dri36lAQGA",
          "https://twitter.com/SUSE",
          "https://www.linkedin.com/company/suse"
    ],
    "publisher": {
      "@type": "Corporation",
      "name": "SUSE",
      "url": "https://documentation.suse.com",
      "logo": {
        "@type": "ImageObject",
        "url": "https://www.suse.com/assets/img/suse-white-logo-green.svg"
      }
    }
  }</script>
<link rel="prev" href="troubleshooting-phone-home-scenarios.html" title="Chapter 49. Troubleshooting Phone-Home scenarios"/><link rel="next" href="troubleshooting-other-components.html" title="Chapter 51. Troubleshooting Other components"/><script type="text/javascript">

if ( window.location.protocol.toLowerCase() != 'file:' ) {
  document.write('<link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css"></link>');
};

</script><noscript><link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css"/></noscript><script src="static/js/script-purejs.js" type="text/javascript"> </script><script src="static/js/highlight.min.js" type="text/javascript"> </script><script>

$(document).ready(function() {
  $('.verbatim-wrap.highlight').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});
hljs.configure({
  useBR: false
});

</script></head><body class="wide offline js-off"><div class="bypass-block"><a href="#_content">Jump to content</a><a href="#_bottom-pagination">Jump to page navigation: previous page [access key p]/next page [access key n]</a></div><header id="_mainnav"><div class="growth-inhibitor"><img src="static/images/logo.svg" alt="Logo" class="logo"/></div></header><div class="crumbs"><div class="growth-inhibitor"><a class="crumb" href="index.html">SUSE Edge Documentation</a><span> / </span><a class="crumb" href="id-troubleshooting-3.html">Troubleshooting</a><span> / </span><a class="crumb" href="troubleshooting-directed-network-provisioning.html">Troubleshooting Directed-network provisioning</a></div></div><main id="_content"><nav id="_side-toc-overall" class="side-toc"><div class="side-title">SUSE Edge Documentation</div><ol><li><a href="suse-edge-documentation.html" class=" "><span class="title-number"> </span><span class="title-name">SUSE Edge 3.4 Documentation</span></a></li><li><a href="id-quick-starts.html" class="has-children "><span class="title-number">I </span><span class="title-name">Quick Starts</span></a><ol><li><a href="quickstart-metal3.html" class=" "><span class="title-number">1 </span><span class="title-name">BMC automated deployments with Metal<sup>3</sup></span></a></li><li><a href="quickstart-elemental.html" class=" "><span class="title-number">2 </span><span class="title-name">Remote host onboarding with Elemental</span></a></li><li><a href="quickstart-eib.html" class=" "><span class="title-number">3 </span><span class="title-name">Standalone clusters with Edge Image Builder</span></a></li><li><a href="quickstart-suma.html" class=" "><span class="title-number">4 </span><span class="title-name">SUSE Multi-Linux Manager</span></a></li></ol></li><li><a href="id-components.html" class="has-children "><span class="title-number">II </span><span class="title-name">Components</span></a><ol><li><a href="components-rancher.html" class=" "><span class="title-number">5 </span><span class="title-name">Rancher</span></a></li><li><a href="components-rancher-dashboard-extensions.html" class=" "><span class="title-number">6 </span><span class="title-name">Rancher Dashboard Extensions</span></a></li><li><a href="components-rancher-turtles.html" class=" "><span class="title-number">7 </span><span class="title-name">Rancher Turtles</span></a></li><li><a href="components-fleet.html" class=" "><span class="title-number">8 </span><span class="title-name">Fleet</span></a></li><li><a href="components-slmicro.html" class=" "><span class="title-number">9 </span><span class="title-name">SUSE Linux Micro</span></a></li><li><a href="components-metal3.html" class=" "><span class="title-number">10 </span><span class="title-name">Metal<sup>3</sup></span></a></li><li><a href="components-eib.html" class=" "><span class="title-number">11 </span><span class="title-name">Edge Image Builder</span></a></li><li><a href="components-nmc.html" class=" "><span class="title-number">12 </span><span class="title-name">Edge Networking</span></a></li><li><a href="components-elemental.html" class=" "><span class="title-number">13 </span><span class="title-name">Elemental</span></a></li><li><a href="components-akri.html" class=" "><span class="title-number">14 </span><span class="title-name">Akri</span></a></li><li><a href="components-k3s.html" class=" "><span class="title-number">15 </span><span class="title-name">K3s</span></a></li><li><a href="components-rke2.html" class=" "><span class="title-number">16 </span><span class="title-name">RKE2</span></a></li><li><a href="components-suse-storage.html" class=" "><span class="title-number">17 </span><span class="title-name">SUSE Storage</span></a></li><li><a href="components-suse-security.html" class=" "><span class="title-number">18 </span><span class="title-name">SUSE Security</span></a></li><li><a href="components-metallb.html" class=" "><span class="title-number">19 </span><span class="title-name">MetalLB</span></a></li><li><a href="components-eco.html" class=" "><span class="title-number">20 </span><span class="title-name">Endpoint Copier Operator</span></a></li><li><a href="components-kubevirt.html" class=" "><span class="title-number">21 </span><span class="title-name">Edge Virtualization</span></a></li><li><a href="components-system-upgrade-controller.html" class=" "><span class="title-number">22 </span><span class="title-name">System Upgrade Controller</span></a></li><li><a href="components-upgrade-controller.html" class=" "><span class="title-number">23 </span><span class="title-name">Upgrade Controller</span></a></li><li><a href="components-suma.html" class=" "><span class="title-number">24 </span><span class="title-name">SUSE Multi-Linux Manager</span></a></li></ol></li><li><a href="id-how-to-guides.html" class="has-children "><span class="title-number">III </span><span class="title-name">How-To Guides</span></a><ol><li><a href="guides-metallb-k3s.html" class=" "><span class="title-number">25 </span><span class="title-name">MetalLB on K3s (using Layer 2 Mode)</span></a></li><li><a href="guides-metallb-k3s-l3.html" class=" "><span class="title-number">26 </span><span class="title-name">MetalLB on K3s (using Layer 3 Mode)</span></a></li><li><a href="guides-metallb-kubernetes.html" class=" "><span class="title-number">27 </span><span class="title-name">MetalLB in front of the Kubernetes API server</span></a></li><li><a href="id-air-gapped-deployments-with-edge-image-builder.html" class=" "><span class="title-number">28 </span><span class="title-name">Air-gapped deployments with Edge Image Builder</span></a></li><li><a href="guides-kiwi-builder-images.html" class=" "><span class="title-number">29 </span><span class="title-name">Building Updated SUSE Linux Micro Images with Kiwi</span></a></li><li><a href="guides-clusterclass-example.html" class=" "><span class="title-number">30 </span><span class="title-name">Using clusterclass to deploy downstream clusters</span></a></li></ol></li><li><a href="tips-and-tricks.html" class="has-children "><span class="title-number">IV </span><span class="title-name">Tips and Tricks</span></a><ol><li><a href="tips-edge-image-builder.html" class=" "><span class="title-number">31 </span><span class="title-name">Edge Image Builder</span></a></li><li><a href="tips-elemental.html" class=" "><span class="title-number">32 </span><span class="title-name">Elemental</span></a></li></ol></li><li><a href="id-third-party-integration.html" class="has-children "><span class="title-number">V </span><span class="title-name">Third-Party Integration</span></a><ol><li><a href="integrations-nats.html" class=" "><span class="title-number">33 </span><span class="title-name">NATS</span></a></li><li><a href="id-nvidia-gpus-on-suse-linux-micro.html" class=" "><span class="title-number">34 </span><span class="title-name">NVIDIA GPUs on SUSE Linux Micro</span></a></li></ol></li><li><a href="day-2-operations.html" class="has-children "><span class="title-number">VI </span><span class="title-name">Day 2 Operations</span></a><ol><li><a href="day2-migration.html" class=" "><span class="title-number">35 </span><span class="title-name">Edge 3.4 migration</span></a></li><li><a href="day2-mgmt-cluster.html" class=" "><span class="title-number">36 </span><span class="title-name">Management Cluster</span></a></li><li><a href="day2-downstream-clusters.html" class=" "><span class="title-number">37 </span><span class="title-name">Downstream clusters</span></a></li></ol></li><li><a href="id-suse-telco-cloud-documentation.html" class="has-children "><span class="title-number">VII </span><span class="title-name">SUSE Telco Cloud Documentation</span></a><ol><li><a href="atip.html" class=" "><span class="title-number">38 </span><span class="title-name">SUSE Telco Cloud</span></a></li><li><a href="atip-architecture.html" class=" "><span class="title-number">39 </span><span class="title-name">Concept &amp; Architecture</span></a></li><li><a href="atip-requirements.html" class=" "><span class="title-number">40 </span><span class="title-name">Requirements &amp; Assumptions</span></a></li><li><a href="atip-management-cluster.html" class=" "><span class="title-number">41 </span><span class="title-name">Setting up the management cluster</span></a></li><li><a href="atip-features.html" class=" "><span class="title-number">42 </span><span class="title-name">Telco features configuration</span></a></li><li><a href="atip-automated-provisioning.html" class=" "><span class="title-number">43 </span><span class="title-name">Fully automated directed network provisioning</span></a></li><li><a href="atip-lifecycle.html" class=" "><span class="title-number">44 </span><span class="title-name">Lifecycle actions</span></a></li></ol></li><li class="active"><a href="id-troubleshooting-3.html" class="has-children you-are-here"><span class="title-number">VIII </span><span class="title-name">Troubleshooting</span></a><ol><li><a href="general-troubleshooting-principles.html" class=" "><span class="title-number">45 </span><span class="title-name">General Troubleshooting Principles</span></a></li><li><a href="troubleshooting-kiwi.html" class=" "><span class="title-number">46 </span><span class="title-name">Troubleshooting Kiwi</span></a></li><li><a href="troubleshooting-edge-image-builder.html" class=" "><span class="title-number">47 </span><span class="title-name">Troubleshooting Edge Image Builder (EIB)</span></a></li><li><a href="troubleshooting-edge-networking.html" class=" "><span class="title-number">48 </span><span class="title-name">Troubleshooting Edge Networking (NMC)</span></a></li><li><a href="troubleshooting-phone-home-scenarios.html" class=" "><span class="title-number">49 </span><span class="title-name">Troubleshooting Phone-Home scenarios</span></a></li><li><a href="troubleshooting-directed-network-provisioning.html" class=" you-are-here"><span class="title-number">50 </span><span class="title-name">Troubleshooting Directed-network provisioning</span></a></li><li><a href="troubleshooting-other-components.html" class=" "><span class="title-number">51 </span><span class="title-name">Troubleshooting Other components</span></a></li><li><a href="collecting-diagnostics-for-support.html" class=" "><span class="title-number">52 </span><span class="title-name">Collecting Diagnostics for Support</span></a></li></ol></li><li><a href="id-appendix.html" class="has-children "><span class="title-number">IX </span><span class="title-name">Appendix</span></a><ol><li><a href="id-release-notes.html" class=" "><span class="title-number">53 </span><span class="title-name">Release Notes</span></a></li></ol></li> </ol> </nav><button id="_open-side-toc-overall" title="Contents"> </button><article class="documentation"><button id="_unfold-side-toc-page">On this page</button><section class="chapter" id="troubleshooting-directed-network-provisioning" data-id-title="Troubleshooting Directed-network provisioning"><div class="titlepage"><div><div><div class="title-container"><h1 class="title"><span class="title-number-name"><span class="title-number">50 </span><span class="title-name">Troubleshooting Directed-network provisioning</span></span> <a title="Permalink" class="permalink" href="troubleshooting-directed-network-provisioning.html#">#</a></h1><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>Directed-network provisioning scenarios involve using Metal<sup>3</sup> and CAPI elements to provision the Downstream cluster. It also includes EIB to create an OS image. Issues can happen when the host is being booted for the first time or during the inspection or provisioning processes.</p><div class="itemizedlist"><div class="title-container"><div class="itemizedlist-title-wrap"><div class="itemizedlist-title"><span class="title-number-name"><span class="title-name">Common Issues </span></span><a title="Permalink" class="permalink" href="troubleshooting-directed-network-provisioning.html#id-1.10.8.3">#</a></div></div><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div><ul class="itemizedlist"><li class="listitem"><p><span class="strong"><strong>Old firmware</strong></span>: Verify all the different firmware on the physical hosts being used are up to date. This includes the BMC firmware as some times Metal<sup>3</sup> <a class="link" href="https://book.metal3.io/bmo/supported_hardware#redfish-and-its-variants" target="_blank">requires specific/updated ones</a>.</p></li><li class="listitem"><p><span class="strong"><strong>Provisioning failed with SSL errors</strong></span>: If the webserver serving the images uses https, Metal<sup>3</sup> needs to be configured to inject and trust the certificate on the IPA image. See Kubernetes folder (<a class="xref" href="atip-management-cluster.html#mgmt-cluster-kubernetes-folder" title="41.3.4. Kubernetes folder">Section 41.3.4, “Kubernetes folder”</a>) on how to include a <code class="literal">ca-additional.crt</code> file to the Metal<sup>3</sup> chart.</p></li><li class="listitem"><p><span class="strong"><strong>Certificates issues when booting the hosts with IPA</strong></span>: Some server vendors verify the SSL connection when attaching virtual-media ISO images to the BMC, which can cause a problem because the generated certificates for the Metal3 deployment are self-signed. It can happen that the host is being booted but it drops to an UEFI shell. See Disabling TLS for virtualmedia ISO attachment (<a class="xref" href="quickstart-metal3.html#disabling-tls-for-virtualmedia-iso-attachment" title="1.7.2. Disabling TLS for virtualmedia ISO attachment">Section 1.7.2, “Disabling TLS for virtualmedia ISO attachment”</a>) on how to fix it.</p></li><li class="listitem"><p><span class="strong"><strong>Wrong name or label reference</strong></span>: If the cluster references a node by the wrong name or label, the cluster results as deployed but the BMH remains as “Available”. Double-check the references on the involved objects for the BMHs.</p></li><li class="listitem"><p><span class="strong"><strong>BMC communication issues</strong></span>: Ensure the Metal<sup>3</sup> pods running on the management cluster can reach the BMC of the hosts being provisioned (usually the BMC network is very restricted).</p></li><li class="listitem"><p><span class="strong"><strong>Incorrect bare metal host state</strong></span>: The BMH object goes to different states (inspecting, preparing, provisioned, etc.) during its lifetime <a class="link" href="https://book.metal3.io/bmo/state_machine" target="_blank">Lifetime of State machine</a>. If detected an incorrect state, check the <code class="literal">status</code> field of the BMH object as it contains more information as <code class="literal">kubectl get bmh &lt;name&gt; -o jsonpath=’{.status}’| jq</code>.</p></li><li class="listitem"><p><span class="strong"><strong>Host not being deprovisioned</strong></span>: In the event of a host being intended to be deprovisioned fails, the removal can be attempted after adding the “detached” annotation to the BMH object as:  <code class="literal">kubectl annotate bmh/&lt;BMH&gt; baremetalhost.metal3.io/detached=””</code>.</p></li><li class="listitem"><p><span class="strong"><strong>Image errors</strong></span>: Verify the image being built with EIB for the downstream cluster is available, has a proper checksum and it is not too large to decompress or too large for disk.</p></li><li class="listitem"><p><span class="strong"><strong>Disk size mismatch</strong></span>: By default, the disk would not expand to fill the whole disk. As explained in the Growfs script (<a class="xref" href="quickstart-metal3.html#growfs-script" title="1.4.4.1.2. Growfs script">Section 1.4.4.1.2, “Growfs script”</a>) section, a growfs script needs to be included in the image being built with EIB for the downstream cluster hosts.</p></li><li class="listitem"><p><span class="strong"><strong>Cleaning process stuck</strong></span>: The cleaning process is retried several times. If due to a problem with the host cleaning is no longer possible, disable cleaning first by setting the <code class="literal">automatedCleanMode</code> field to <code class="literal">disabled</code> on the BMH object.</p><div id="id-1.10.8.3.11.2" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.svg"/><div class="admon-title">Warning</div><p>It is not recommended to manually remove the finalizer when the cleaning process is taking longer than desired or is failing. Doing so, removes the host record from Kubernetes but leave it in Ironic. The currently running action continues in the background, and an attempt to add the host again may fail because of the conflict.</p></div></li><li class="listitem"><p><span class="strong"><strong>Metal3/Rancher Turtles/CAPI pods issues</strong></span>: The deployment flow for all the required components is:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>The Rancher Turtles controller deploys the CAPI operator controller.</p></li><li class="listitem"><p>The CAPI operator controller then deploys the provider controllers (CAPI core, CAPM3 and RKE2 controlplane/bootstrap).</p></li></ul></div></li></ul></div><p>Verify all the pods are running correctly and check the logs otherwise.</p><div class="itemizedlist"><div class="title-container"><div class="itemizedlist-title-wrap"><div class="itemizedlist-title"><span class="title-number-name"><span class="title-name">Logs </span></span><a title="Permalink" class="permalink" href="troubleshooting-directed-network-provisioning.html#id-1.10.8.5">#</a></div></div><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div><ul class="itemizedlist"><li class="listitem"><p><span class="strong"><strong>Metal<sup>3</sup> logs</strong></span>:Check logs for the different pods.</p><div class="verbatim-wrap"><pre class="screen">kubectl logs -n metal3-system -l app.kubernetes.io/component=baremetal-operator
kubectl logs -n metal3-system -l app.kubernetes.io/component=ironic</pre></div><div id="id-1.10.8.5.2.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><p>The metal3-ironic pod contains at least 4 different containers (<code class="literal">ironic-httpd</code>,` ironic-log-watch`, <code class="literal">ironic</code> &amp; <code class="literal">ironic-ipa-downloader</code> (init)) on the same pod. Use the <code class="literal">-c</code>  flag when using <code class="literal">kubectl logs</code> to verify the logs of each of the containers.</p></div><div id="id-1.10.8.5.2.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><p>The <code class="literal">ironic-log-watch</code> container exposes console logs from the hosts after inspection/provisioning, provided network connectivity enables sending these logs back to the management cluster. This can be useful in cases where there are provisioning errors but you do not have direct access to the BMC console logs.</p></div></li><li class="listitem"><p><span class="strong"><strong>Rancher Turtles logs</strong></span>: Check logs for the different pods.</p><div class="verbatim-wrap"><pre class="screen">kubectl logs -n rancher-turtles-system -l control-plane=controller-manager
kubectl logs -n rancher-turtles-system -l app.kubernetes.io/name=cluster-api-operator
kubectl logs -n rke2-bootstrap-system -l cluster.x-k8s.io/provider=bootstrap-rke2
kubectl logs -n rke2-control-plane-system -l cluster.x-k8s.io/provider=control-plane-rke2
kubectl logs -n capi-system -l cluster.x-k8s.io/provider=cluster-api
kubectl logs -n capm3-system -l cluster.x-k8s.io/provider=infrastructure-metal3</pre></div></li><li class="listitem"><p><span class="strong"><strong>BMC logs</strong></span>: Usually BMCs have a UI where most of the interaction can be done. There is usually a “logs” section that can be observed for potential issues (not being able to reach the image, hardware failures, etc.).</p></li><li class="listitem"><p><span class="strong"><strong>Console logs</strong></span>: Connect to the BMC console (via the BMC webui, serial, etc.) and check for errors on the logs being written.</p></li></ul></div><div class="orderedlist"><div class="title-container"><div class="orderedlist-title-wrap"><div class="orderedlist-title"><span class="title-number-name"><span class="title-name">Troubleshooting steps </span></span><a title="Permalink" class="permalink" href="troubleshooting-directed-network-provisioning.html#id-1.10.8.6">#</a></div></div><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div><ol class="orderedlist" type="1"><li class="listitem"><p><span class="strong"><strong>Check <code class="literal">BareMetalHost</code> status</strong></span>:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p><code class="literal">kubectl get bmh -A</code> shows the current state. Look for <code class="literal">provisioning</code>, <code class="literal">ready</code>, <code class="literal">error</code>, <code class="literal">registering</code>.</p></li><li class="listitem"><p><code class="literal">kubectl describe bmh -n &lt;namespace&gt; &lt;bmh_name&gt;</code> provides detailed events and conditions explaining why a BMH might be stuck.</p></li></ul></div></li><li class="listitem"><p><span class="strong"><strong>Test RedFish connectivity</strong></span>:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Use <code class="literal">curl</code> from the Metal<sup>3</sup> control plane to test connectivity to the BMCs via redfish.</p></li><li class="listitem"><p>Ensure correct BMC credentials are provided in the <code class="literal">BareMetalHost-Secret</code> definition.</p></li></ul></div></li><li class="listitem"><p><span class="strong"><strong>Verify turtles/CAPI/metal3 pod status</strong></span>: Ensure the containers on the management cluster are up and running: <code class="literal">kubectl get pods -n metal3-system</code> and <code class="literal">kubectl get pods -n rancher-turtles-system</code> (also see <code class="literal">capi-system</code>, <code class="literal">capm3-system</code>, <code class="literal">rke2-bootstrap-system</code> and <code class="literal">rke2-control-plane-system</code>).</p></li><li class="listitem"><p><span class="strong"><strong>Verify the ironic endpoint is reachable from the host being provisioned</strong></span>: The host being provisioned needs to be able to reach out the Ironic endpoint to report back to Metal<sup>3</sup>. Check the IP with <code class="literal">kubectl get svc -n metal3-system metal3-metal3-ironic</code> and try to reach it via <code class="literal">curl/nc</code>.</p></li><li class="listitem"><p><span class="strong"><strong>Verify the IPA image is reachable from the BMC</strong></span>: IPA is being served by the Ironic endpoint and it needs to be reachable from the BMC as it is being used as a virtual CD.</p></li><li class="listitem"><p><span class="strong"><strong>Verify the OS image is reachable from the host being provisioned</strong></span>: The image being used to provision the host needs to be reachable from the host itself (when running IPA) as it will be downloaded temporarily and written to the disk.</p></li><li class="listitem"><p><span class="strong"><strong>Examine Metal<sup>3</sup> component logs</strong></span>: See above.</p></li><li class="listitem"><p><span class="strong"><strong>Retrigger BMH Insepction</strong></span>:  If an inspection failed or the hardware of an available host changed, a new inspection process can be triggered by annotating the BMH object with <code class="literal">inspect.metal3.io: ""</code>. See the <a class="link" href="https://book.metal3.io/bmo/inspect_annotation" target="_blank">Metal<sup>3</sup> Controlling inspection</a> guide for more information.</p></li><li class="listitem"><p><span class="strong"><strong>Bare metal IPA console</strong></span>: To troubleshoot IPA issues a couple of alternatives exist:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Enable “autologin”. This enables the root user to be logged automatically when connecting to the IPA console.</p><div id="id-1.10.8.6.10.2.1.2" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.svg"/><div class="admon-title">Warning</div><p>This is only for debug purposes as it gives full access to the host.</p></div><p>To enable autologin, the Metal3 helm <code class="literal">global.ironicKernelParams</code> value should look like: <code class="literal">console=ttyS0 suse.autologin=ttyS0</code> (depending on the console, <code class="literal">ttyS0</code> can be changed). Then a redeployment of the Metal<sup>3</sup> chart should be performed. (Note <code class="literal">ttyS0</code> is an example, this should match the actual terminal e.g may be <code class="literal">tty1</code> in many cases on bare metal, this can be verified by looking at the console output from the IPA ramdisk on boot where <code class="literal">/etc/issue</code> prints the console name).</p><p>Another way to do it is by changing the <code class="literal">IRONIC_KERNEL_PARAMS</code> parameter on the <code class="literal">ironic-bmo</code> configmap on the <code class="literal">metal3-system</code> namespace. This can be easier as it can be done via <code class="literal">kubectl</code> edit but it will be overwritten when updating the chart. Then the Metal<sup>3</sup> pod needs to be restarted with <code class="literal">kubectl delete pod -n metal3-system -l app.kubernetes.io/component=ironic</code>.</p></li><li class="listitem"><p>Inject an ssh key for the root user on the IPA.</p><div id="id-1.10.8.6.10.2.2.2" class="admonition warning normal"><img class="symbol" alt="Warning" title="Warning" src="static/images/icon-warning.svg"/><div class="admon-title">Warning</div><p>This is only for debug purposes as it gives full access to the host.</p></div><p>To inject the ssh key for the root user, the Metal<sup>3</sup> helm <code class="literal">debug.ironicRamdiskSshKey</code> value should be used. Then a redeployment of the Metal<sup>3</sup> chart should be performed.</p><p>Another way to do it is by changing the <code class="literal">IRONIC_RAMDISK_SSH_KEY</code> parameter on the <code class="literal">ironic-bmo configmap</code> on the <code class="literal">metal3-system</code> namespace. This can be easier as it can be done via <code class="literal">kubectl</code> edit but it will be overwritten when updating the chart. Then the Metal<sup>3</sup> pod needs to be restarted with <code class="literal">kubectl delete pod -n metal3-system -l app.kubernetes.io/component=ironic</code></p></li></ul></div></li></ol></div><div id="id-1.10.8.7" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><p>Check the <a class="link" href="https://cluster-api.sigs.k8s.io/user/troubleshooting" target="_blank">CAPI troubleshooting</a> and <a class="link" href="https://book.metal3.io/troubleshooting" target="_blank">Metal<sup>3</sup> troubleshooting</a> guides.</p></div></section><nav class="bottom-pagination"><div><a class="pagination-link prev" href="troubleshooting-phone-home-scenarios.html"><span class="pagination-relation">Previous</span><span class="pagination-label"><span class="title-number">Chapter 49 </span>Troubleshooting Phone-Home scenarios</span></a> </div><div><a class="pagination-link next" href="troubleshooting-other-components.html"><span class="pagination-relation">Next</span><span class="pagination-label"><span class="title-number">Chapter 51 </span>Troubleshooting Other components</span></a> </div></nav></article><aside id="_side-toc-page" class="side-toc"><div class="side-title">Share this page</div><ul class="share"><li><a id="_share-fb" href="#" title="Facebook"> </a></li><li><a id="_share-in" href="#" title="LinkedIn"> </a></li><li><a id="_share-tw" href="#" title="Twitter/X"> </a></li><li><a id="_share-mail" href="#" title="E-Mail"> </a></li><li><a id="_print-button" href="#" title="Print this page"> </a></li></ul> </aside></main><footer id="_footer"><div class="growth-inhibitor"><div class="copy"><span class="copy__rights">© SUSE
                 2025</span></div></div></footer></body></html>