[#atip-requirements]
== Requirements & Assumptions
:experimental:

ifdef::env-github[]
:imagesdir: ../images/
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]

=== Hardware

The hardware requirements for the ATIP nodes are based on the following components:

* **Management cluster**: The management cluster contains components like `SLE Micro`, `RKE2`, `Rancher Prime`, `Metal^3^`, and it is used to manage several downstream clusters. Depending on the number of downstream clusters to be managed, the hardware requirements for the server could vary.
  ** Minimum requirements for the server (`VM` or `bare-metal`) are:
     *** RAM: 8 GB Minimum (we recommend at least 16 GB)
     *** CPU: 2 Minimum (we recommend at least 4 CPU)

* **Downstream clusters**: The downstream clusters are the clusters deployed on the ATIP nodes to run Telco workloads. Specific requirements are needed to enable certain Telco capabilities like `SR-IOV`, `CPU Performance Optimization`, etc.
  ** SR-IOV: to attach VFs (Virtual Functions) in pass-through mode to CNFs/VNFs, the NIC must support SR-IOV and VT-d/AMD-Vi be enabled in the BIOS.
  ** CPU Processors: To run specific Telco workloads, the CPU Processor model should be adapted to enable most of the features available in this reference <<atip-features,table>>.
  ** Firmware requirements for installing with virtual media:

|===
| Server Hardware | BMC Model | Management
| Dell hardware
| 15th Generation
| iDRAC9

| Supermicro hardware
| 01.00.25
| Supermicro SMC - redfish

| HPE hardware
| 1.50
| iLO6
|===


=== Network

As a reference for the network architecture, the following diagram shows a typical network architecture for a Telco environment:

image::product-atip-requirement1.png[]

The network architecture is based on the following components:

* **Management network**: This network is used for the management of the ATIP nodes. It is used for the out-of-band management. Usually, this network is also connected to a separate management switch, but it can be connected to the same service switch using VLANs to isolate the traffic.
* **Control-plane network**: This network is used for the communication between the ATIP nodes and the services that are running on them. This network is also used for the communication between the ATIP nodes and the external services, like the `DHCP` or `DNS` servers. In some cases, for connected environments, the switch/router can handle traffic through the Internet.
* **Other networks**: In some cases, the ATIP nodes could be connected to other networks for specific customer purposes.

[NOTE]
====
To use the directed network provisioning workflow, the management cluster must have network connectivity to the downstream cluster server Baseboard Management Controller (BMC) so that host preparation and provisioning can be automated.
====

=== Services (DHCP, DNS, etc.)

Some external services like `DHCP`, `DNS`, etc. could be required depending on the kind of environment where they are deployed:

* **Connected environment**: In this case, the ATIP nodes will be connected to the Internet (via routing L3 protocols) and the external services will be provided by the customer.
* **Disconnected / air-gap environment**: In this case, the ATIP nodes will not have Internet IP connectivity and additional services will be required to locally mirror content required by the ATIP directed network provisioning workflow.
* **File server**: A file server is used to store the ISO images to be provisioned on the ATIP nodes during the directed network provisioning workflow. The `metal^3^` Helm chart can deploy a media server to store the ISO images â€” check the following xref:metal3-media-server[section], but it is also possible to use an existing local webserver.

=== Disabling rebootmgr

`rebootmgr` is a service which allows to configure a strategy for reboot when the system has pending updates.
For Telco workloads, it is really important to disable or configure properly the `rebootmgr` service to avoid the reboot of the nodes in case of updates scheduled by the system, to avoid any impact on the services running on the nodes.

[NOTE]
====
For more information about `rebootmgr`, see https://github.com/SUSE/rebootmgr[rebootmgr GitHub repository].
====

Verify the strategy being used by running:

[,shell]
----
cat /etc/rebootmgr.conf
[rebootmgr]
window-start=03:30
window-duration=1h30m
strategy=best-effort
lock-group=default
----

and you could disable it by running:

[,shell]
----
sed -i 's/strategy=best-effort/strategy=off/g' /etc/rebootmgr.conf
----

or using the `rebootmgrctl` command:

[,shell]
----
rebootmgrctl strategy off
----

[NOTE]
====
This configuration to set the `rebootmgr` strategy can be automated using the directed network provisioning workflow. For more information, check the <<atip-automated-provisioning,ATIP Automated Provisioning documentation>>.
====
