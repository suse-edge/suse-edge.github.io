[#day2-os-package-update]
== OS package update
:experimental:

ifdef::env-github[]
:imagesdir: ../images/
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
endif::[]
:toc: auto

=== Components

This section covers the general components that are used to achieve an OS pacakge update:

* <<components-rancher,Rancher>> - Located on the <<day2-mgmt-cluster,Rancher Management Cluster>>; responsible for the downstream cluster management. *For use-cases where you want to utilise <<components-fleet,Fleet>> without Rancher, you can skip the Rancher component all together.*

* <<components-fleet,Fleet>> - Service offered by the `Rancher` component; responsible for muti-cluster resource deployment. Alternatively, if you are not using `Rancher`, `Fleet` can be deployed as a standalone component. For more information, see link:https://fleet.rancher.io/installation[Installation Details].

* link:https://github.com/rancher/system-upgrade-controller[system-upgrade-controller] (*SUC*) - Located on each downstream cluster; responsible for executing tasks on specified nodes based on configuration data providede throguh a custom resource, called a `Plan`. For information on how to setup *SUC*, see <<day2-suc-deployment-guide>>

* `edge-update.service` - link:https://www.freedesktop.org/software/systemd/man/latest/systemd.service.html[systemd.service] located on each downstream cluster node; responsible for performing the OS packages update using the `transactional-update` command. Shipped to each downstream cluster through the `system-upgrade-controller` Plan resource.

=== Requirements

_General:_

. *SCC registered machine* - All downstream cluster nodes should be registered to `https://scc.suse.com/`. This is needed so that the `edge-update.service` can successfully connect to the needed OS RPM repositories.

. *Make sure that SUC Plan tolerations match node tolerations* - If your Kubernetes cluster nodes have custom *taints*, make sure to add link:https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/[tolerations] for those taints in the *SUC Plans*. By default *SUC Plans* have tolerations only for *control-plane* nodes. Default tolerations include:

* _CriticalAddonsOnly=true:NoExecute_

* _node-role.kubernetes.io/control-plane:NoSchedule_

* _node-role.kubernetes.io/etcd:NoExecute_
+
[NOTE]
====
Any additional tolerations must be added under the `.spec.tolerations` section of each Plan. *SUC Plans* related to the OS package update can be found in the link:https://github.com/ipetrov117/fleet-examples[suse-edge/fleet-examples] repository under `fleets/day2/system-upgrade-controller-plans/os-pkg-update`. *Make sure you use the Plans from a valid repository link:https://github.com/ipetrov117/fleet-examples/releases[release] tag.*

An example of defining custom tolerations for the *control-plane* SUC Plan, would look like this:
[,yaml]
----
apiVersion: upgrade.cattle.io/v1
kind: Plan
metadata:
  name: os-pkg-plan-control-plane
spec:
  ...
  tolerations:
  # default tolerations
  - key: "CriticalAddonsOnly"
    operator: "Equal"
    value: "true"
    effect: "NoExecute"
  - key: "node-role.kubernetes.io/control-plane"
    operator: "Equal"
    effect: "NoSchedule"
  - key: "node-role.kubernetes.io/etcd"
    operator: "Equal"
    effect: "NoExecute"
  # custom toleration
  - key: "foo"
    operator: "Equal"
    value: "bar"
    effect: "NoSchedule"
...
----
====

. *Make sure you are using the correct update mechanism* - The `edge-update.service` that is shipped with the *SUC OS package update Plans* performs a link:https://en.opensuse.org/SDB:Zypper_usage#Distribution_upgrade[distribution upgrade] (`dup`) by default. If you wish to use a link:https://en.opensuse.org/SDB:Zypper_usage#Updating_packages[normal upgrade] method, create a `edge-update.conf` file under `/etc/edge/` on each node. Inside this file, add the `UPDATE_METHOD=up` variable

_Air-gapped:_

. *Mirror SUSE RPM repositories* - OS RPM repositories should be locally mirrored so that `edge-update.service` can have access to them. This can be achieved using link:https://github.com/SUSE/rmt[RMT].

=== Update procedure

[NOTE]
====
This section assumes you will be deploying *SUC Plans* using <<components-fleet,Fleet>>. If you intend to deploy the *SUC Plan* using a different approach, refer to <<os-pkg-suc-plan-deployment-third-party>>.
====

The `OS package update procedure` revolves around deploying *SUC Plans* to downstream clusters. These plans hold information that instructs the *SUC* on how to perform OS package update on *each* of the downstream cluster nodes. For information regarding the structure of a *SUC Plan*, refer to the https://github.com/rancher/system-upgrade-controller?tab=readme-ov-file#example-plans[upstream] documentation.

Deployment orchestration for these *Plans* is done by using either a *GitRepo* or a *Bundle* resource. 

A *GitRepo* resource represents a Git repository from which *Fleet* creates *Bundles*. While *Bundles* are resources that hold the *raw* Kubernetes resources that will be deployed on the targeted cluster. For more information, refer to the https://fleet.rancher.io/gitrepo-add[GitRepo] and https://fleet.rancher.io/bundle-add[Bundle] documentations.

Whether to use the *GitRepo* or *Bundle* resource depends on your use-case, refer to the <<os-pkg-update-determine-use-case>> section for more information.

For a full overview of what happens during the _update procedure_, refer to the <<os-pkg-update-overview>> section.

[#os-pkg-update-determine-use-case]
==== Determine use-case

This section aims at helping users determine which Fleet resource (*GitRepo* or *Bundle*) is more suited to deploy the `OS package update SUC Plans` based on the environment's use-case.

===== GitRepo

*GitRepo* resources are normally used to deploy *SUC Plans* on *non air-gapped* environments that utilise a _Fleet GitOps_ approach.

Alternatively, *GitRepo* resources can also be used to deploy *SUC Plans* on *air-gapped* environments, *if you mirror your repository setup through a local git server*.

The Edge team maintains ready to use *GitRepo* resource for the *SUC Plans* related to OS package updages in our link:https://github.com/ipetrov117/fleet-examples[suse-edge/fleet-examples] repository under `gitrepos/day2/os-pkg-update-gitrepo.yaml`.

[NOTE]
====
If your use-case does not require any additional custom configurations over the *GitRepo* resource, or any related to the resource `fleets` (e.g. the underlying update Plan resources), you can directly use the *GitRepo* from the `suse-edge/fleet-examples` repository.
====

[IMPORTANT]
====
If using the `suse-edge/fleet-examples` repository, make sure you are using the *GitRepo* resources from a dedicated link:https://github.com/ipetrov117/fleet-examples/releases[release] tag.
====

For information on how to deploy the *OS package update SUC Plans* using Fleet's *GitRepo* resource, refer to the <<os-pkg-suc-plan-deployment-git-repo>> section.

===== Bundle

*Bundle* resources are normally used to deploy *SUC Plans* on *air-gapped* environments that do not use some form of _local GitOps_ procedure (e.g. a *local git server*).

Alternatively, if your use-case does not allow for a _GitOps_ workflow, *Bundle* resources could also be used to deploy *SUC Plans* on *non air-gapped* environments. 

The Edge team maintains ready to use *Bundle* resource for the *SUC Plans* related to OS package updages in our link:https://github.com/ipetrov117/fleet-examples[suse-edge/fleet-examples] repository under `bundles/day2/system-upgrade-controller-plans/os-pkg-update/pkg-update-bundle.yaml`.

[NOTE]
====
If your use-case does not require any additional custom configurations over the *Bundle* resource, you can directly use it from the `suse-edge/fleet-examples` repository.
====

[IMPORTANT]
====
If using the `suse-edge/fleet-examples` repository, make sure you are using the *Bundle* resource from a dedicated link:https://github.com/ipetrov117/fleet-examples/releases[release] tag.
====

For information on how to deploy the *OS package update SUC Plans* using Fleet's *Bundle* resource, refer to the <<os-pkg-suc-plan-deployment-bundle>> section.

[#os-pkg-update-overview]
==== Overview

This section aims to describe the full workflow that the *_OS package update process_* goes throught from start to finish.

.OS package update workflow
image::day2_os_pkg_update_diagram.png[]

OS pacakge update steps:

. Based on his use-case, the user determines whether to use a *GitRepo* or a *Bundle* resource for the deployment of the `OS package update SUC Plans` to the desired downstream clusters. For information on how to map a *GitRepo/Bundle* to a specific set of downstream clusters, see https://fleet.rancher.io/gitrepo-targets[Mapping to Downstream Clusters].

.. If you are unsure whether you should use a *GitRepo* or a *Bundle* resource for the *SUC Plan* deployment, refer to <<os-pkg-update-determine-use-case>>.

.. For *GitRepo/Bundle* configuration options, refer to <<os-pkg-suc-plan-deployment-git-repo>> or <<os-pkg-suc-plan-deployment-bundle>>.

. The user deploys the configured *GitRepo/Bundle* resource to the `fleet-default` namespace in his <<day2-mgmt-cluster,Rancher Management Cluster>>. This is done either *manually* or thorugh the *Rancher UI* if such is available.

. <<components-fleet,Fleet>> constantly monitors the `fleet-default` namespace and immediately detects the newly deployed *GitRepo/Bundle* resource. For more information regarding what namespaces does Fleet monitor, refer to Fleet's https://fleet.rancher.io/namespaces[Namespaces] documentation.

. If the user has deployed a *GitRepo* resource, `Fleet` will reconcile the *GitRepo* and based on its *paths* and *fleet.yaml* configurations it will deploy a *Bundle* resource in the `fleet-default` namespace. For more information, refer to Fleet's https://fleet.rancher.io/gitrepo-content[GitRepo Contents] documentation.

. `Fleet` then proceeds to deploy the `Kubernetes resources` from this *Bundle* to all the targeted `downstream clusters`. In the context of `OS package updates`, Fleet deploys the following resources from the *Bundle*:

.. `os-pkg-plan-agent` *SUC Plan* - instructs *SUC* on how to do a package update on cluster *_agent_* nodes. Will *not* be interpreted if the cluster consists only from _control-plane_ nodes.

.. `os-pkg-plan-control-plane` *SUC Plan* - instructs *SUC* on how to do a package update on cluster *_control-plane_* nodes.

.. `os-pkg-update` *Secret* - referenced in each *SUC Plan*; ships an `update.sh` script responsible for creating the `edge-update.service` *_sustemd.service_* which will do the actual package update.
+
[NOTE]
====
The above resources will be deployed in the `cattle-system` namespace of each downstream cluster.
====

. On the downstream cluster, *SUC* picks up the newly deployed *SUC Plans* and deploys an *_Update Pod_* on each node that matches the *node selector* defined in the *SUC Plan*. For information how to monitor the *SUC Plan Pod*, refer to <<monitor_suc_plans>>.

. The *Update Pod* (deployed on each node) *mounts* the `os-pkg-update` Secret and *executes* the `update.sh` script that the Secret ships.

. The `update.sh` proceeds to do the following:

.. Create the `edge-update.service` - the service created will be of type *oneshot* and will adopt the following workflow:

... Update all package versions on the node OS, by executing:
+
[,bash]
----
transactional-update cleanup dup
----

... After a successful `transactional-update`, shedule a system *reboot* so that the package version updates can take effect
+
[NOTE]
====
System reboot will be scheduled for *1 minute* after a successful `transactional-update` execution.
====

.. Start the `edge-update.service` and wait for it to complete

.. Cleanup the `edge-update.service` - after the *_systemd.service_* has done its job, it is removed from the system in order to ensure that no accidental executions/reboots happen in the future.

The OS package update procedure finishes with the *_system reboot_*. After the reboot all OS package versions should be updated to their respective latest version as seen in the available OS RPM repositories.

[#os-pkg-suc-plan-deployment]
=== OS package update - SUC Plan deployment

This section describes how to orchestrate the deployment of *SUC Plans* related OS package updates using Fleet's *GitRepo* and *Bundle* resources.

[#os-pkg-suc-plan-deployment-git-repo]
==== SUC Plan deployment - GitRepo resource

A *GitRepo* resource, that ships the needed OS package update *SUC Plans*, can be deployed in one of the following ways:

. Through the `Rancher UI` - if you have a `Rancher` instance available in your environmnet.

. By manually deploying the *GitRepo* resource in the correct *Fleet* namespace - for environments that do not have a `Rancher` instance available.

Once deployed, to monitor the OS package update process of the nodes of your targeted cluster, refer to the <<monitor_suc_plans>> documentation.

===== GitRepo creation - Rancher UI

. In the upper left corner, *☰ -> Continuous Delivery*

. Go to *Git Repos -> Add Repository*

If you use the `suse-edge/fleet-examples` repository:

. *Repository URL* - `https://github.com/ipetrov117/fleet-examples.git`

. *Watch -> Revision* - choose a link:https://github.com/ipetrov117/fleet-examples/releases[release] tag for the `suse-edge/fleet-examples` repository that you wish to use

. Under *Paths* add the path to the OS package update Fleets that you wish to use - `fleets/day2/system-upgrade-controller-plans/os-pkg-update`

. Select *Next* to move to the *target* configuration section. *Only select clusters whose node's packages you wish to upgrade*

. *Create*

Alternatively, if you decide to use your own repository to host these files, you would need to provide your repo data above.

===== GitRepo creation - manual

. Choose the desired Edge link:https://github.com/ipetrov117/fleet-examples/releases[release] tag that you wish to apply the OS *SUC update Plans* from (referenced below as `$\{REVISION\}`).

. Pull the *GitRepo* resource:
+
[,bash]
----
curl -o os-pkg-update-gitrepo.yaml https://raw.githubusercontent.com/ipetrov117/fleet-examples/${REVISION}/gitrepos/day2/os-pkg-update-gitrepo.yaml
----

. Edit the *GitRepo* configuration, under `spec.targets` specify your desired target list. By default the `GitRepo` resources from the `suse-edge/fleet-examples` are *NOT* mapped to any down stream clusters.

** To match all clusters change the default `GitRepo` *target* to:
+
[,yaml]
----
spec:
  targets:
  - clusterSelector: {}
----

** Alternatively, if you want a more granular cluster selection see link:https://fleet.rancher.io/gitrepo-targets[Mapping to Downstream Clusters]


. Apply the *GitRepo* resources to your *Rancher Management Cluster*:
+
[,bash]
----
kubectl apply -f os-pkg-update-gitrepo.yaml
----

. View the created *GitRepo* resource under the `fleet-default` namespace:
+
[,bash]
----
kubectl get gitrepo os-pkg-update -n fleet-default

# Example output
NAME            REPO                                               COMMIT       BUNDLEDEPLOYMENTS-READY   STATUS
os-pkg-update   https://github.com/ipetrov117/fleet-examples.git   edge-3.0.0   0/0                       
----

[#os-pkg-suc-plan-deployment-bundle]
==== SUC Plan deployment - Bundle resource

A *Bundle* resource, that ships the needed OS package update *SUC Plans*, can be deployed in one of the following ways:

. Through the `Rancher UI` - if you have a `Rancher` instance available in your environmnet.

. By manually deploying the *Bundle* resource in the correct *Fleet* namespace - for environments that do not have a `Rancher` instance available.

Once deployed, to monitor the OS package update process of the nodes of your targeted cluster, refer to the <<monitor_suc_plans>> documentation.

===== Bundle creation - Rancher UI

. In the upper left corner, click *☰ -> Continuous Delivery*

. Go to *Advanced* > *Bundles*

. Select *Create from YAML*

. From here you can create the Bundle in one of the following ways:

.. By manually copying the *Bundle* content to the *Create from YAML* page. Content can be retrieved from https://raw.githubusercontent.com/ipetrov117/fleet-examples/$\{REVISION\}/bundles/day2/system-upgrade-controller-plans/os-pkg-update/pkg-update-bundle.yaml, where `$\{REVISION\}` is the Edge link:https://github.com/ipetrov117/fleet-examples/releases[release] that you are using

.. By cloning the link:https://github.com/ipetrov117/fleet-examples.git[suse-edge/fleet-examples] repository to the desired link:https://github.com/ipetrov117/fleet-examples/releases[release] tag and selecting the *Read from File* option in the *Create from YAML* page. From there, navigate to `bundles/day2/system-upgrade-controller-plans/os-pkg-update` directory and select `pkg-update-bundle.yaml`. This will auto-populate the *Create from YAML* page with the Bundle content.

. Change the *target* clusters for the `Bundle`:

** To match all downstream clusters change the default Bundle `.spec.targets` to:
+
[, yaml]
----
spec:
  targets:
  - clusterSelector: {}
----

** For a more granular downstream cluster mappings, see link:https://fleet.rancher.io/gitrepo-targets[Mapping to Downstream Clusters].

. Select *Create*

===== Bundle creation - manual

. Choose the desired Edge link:https://github.com/ipetrov117/fleet-examples/releases[release] tag that you wish to apply the OS package update *SUC Plans* from (referenced below as `$\{REVISION\}`).

. Pull the *Bundle* resource:
+
[,bash]
----
curl -o pkg-update-bundle.yaml https://raw.githubusercontent.com/ipetrov117/fleet-examples/${REVISION}/bundles/day2/system-upgrade-controller-plans/os-pkg-update/pkg-update-bundle.yaml
----

. Edit the `Bundle` *target* configurations, under `spec.targets` provide your desired target list. By default the `Bundle` resources from the `suse-edge/fleet-examples` are *NOT* mapped to any down stream clusters.

** To match all clusters change the default `Bundle` *target* to:
+
[, yaml]
----
spec:
  targets:
  - clusterSelector: {}
----

** Alternatively, if you want a more granular cluster selection see link:https://fleet.rancher.io/gitrepo-targets[Mapping to Downstream Clusters]

. Apply the *Bundle* resources to your *Rancher Management Cluster*:
+
[,bash]
----
kubectl apply -f pkg-update-bundle.yaml
----

. View the created *Bundle* resource under the `fleet-default` namespace:
+
[,bash]
----
kubectl get bundles os-pkg-update -n fleet-default

# Example output
NAME            BUNDLEDEPLOYMENTS-READY   STATUS
os-pkg-update   0/0                       
----

[#os-pkg-suc-plan-deployment-third-party]
==== SUC Plan deployment - third-party GitOps workflow

There might be use-cases where users would like to incorporate the OS package update *SUC Plans* to their own third-party GitOps workflow (e.g. `Flux`).

To get the OS package update resources that you need, first determine the Edge link:https://github.com/ipetrov117/fleet-examples/releases[release] tag of the link:https://github.com/ipetrov117/fleet-examples.git[suse-edge/fleet-examples] repository that you would like to use.

After that, resources can be found at `fleets/day2/system-upgrade-controller-plans/os-pkg-update`, where:

* `plan-control-plane.yaml` - `system-upgrade-controller` Plan resource for *control-plane* nodes

* `plan-agent.yaml` - `system-upgrade-controller` Plan resource for *agent* nodes

* `secret.yaml` - secret that ships a script that creates the `edge-update.service` link:https://www.freedesktop.org/software/systemd/man/latest/systemd.service.html[systemd.service]

[IMPORTANT]
====
These `Plan` resources are interpreted by the `system-upgrade-controller` and should be deployed on each downstream cluster that you wish to upgrade. For information on how to deploy the `system-upgrade-controller`, see <<third_party_git_ops>>.
====

To better understand how your GitOps workflow can be used to deploy the *SUC Plans* for OS package update, it can be beneficial to take a look at the <<os-pkg-update-overview,overview>> of the update procedure using `Fleet`.