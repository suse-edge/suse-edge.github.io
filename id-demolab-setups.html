<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><title>SUSE Edge Documentation | Demo/Lab Setups</title><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes"/><link rel="stylesheet" type="text/css" href="static/css/style.css"/>
<link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"/><link rel="schema.DCTERMS" href="http://purl.org/dc/terms/"/>
<meta name="title" content="Demo/Lab Setups"/>
<meta name="description" content="Via the official docs:"/>
<meta name="book-title" content="SUSE Edge Documentation"/>
<meta name="chapter-title" content="Chapter 1. Demo/Lab Setups"/>
<meta name="tracker-url" content="https://github.com/suse-edge/suse-edge.github.io/issues/new"/>
<meta name="tracker-type" content="gh"/>
<meta name="publisher" content="SUSE"/><meta property="og:title" content="Demo/Lab Setups"/>
<meta property="og:description" content="Via the official docs:"/>
<meta property="og:type" content="article"/>
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Demo/Lab Setups"/>
<meta name="twitter:description" content="Via the official docs:"/>
<script type="application/ld+json">{
    "@context": "http://schema.org",
    "@type": ["TechArticle"],
    "image": "https://www.suse.com/assets/img/suse-white-logo-green.svg",
    
    "inLanguage": "en",
    
    "headline": "Demo/Lab Setups",
  
    "description": "Demo/Lab Setups",
      
    "author": [
      {
        "@type": "Corporation",
        "name": "SUSE Product &amp; Solution Documentation Team",
        "url": "https://www.suse.com/assets/img/suse-white-logo-green.svg"
      }
    ],
      
    "dateModified": "2024-03-27T00:00+02:00",
      

    "about": [
      
    ],
  
    "sameAs": [
          "https://www.facebook.com/SUSEWorldwide/about",
          "https://www.youtube.com/channel/UCHTfqIzPKz4f_dri36lAQGA",
          "https://twitter.com/SUSE",
          "https://www.linkedin.com/company/suse"
    ],
    "publisher": {
      "@type": "Corporation",
      "name": "SUSE",
      "url": "https://documentation.suse.com",
      "logo": {
        "@type": "ImageObject",
        "url": "https://www.suse.com/assets/img/suse-white-logo-green.svg"
      }
    }
  }</script>
<link rel="prev" href="id-quickstarts.html" title="Part I. Quickstarts"/><link rel="next" href="id-standalone-clusters-with-edge-image-builder.html" title="Chapter 2. Standalone Clusters with Edge Image Builder"/><script type="text/javascript">

if ( window.location.protocol.toLowerCase() != 'file:' ) {
  document.write('<link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css"></link>');
};

</script><noscript><link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css"/></noscript><script src="static/js/script-purejs.js" type="text/javascript"> </script><script src="static/js/highlight.min.js" type="text/javascript"> </script><script>

$(document).ready(function() {
  $('.verbatim-wrap.highlight').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});
hljs.configure({
  useBR: false
});

</script></head><body class="wide offline js-off"><div class="bypass-block"><a href="#_content">Jump to content</a><a href="#_bottom-pagination">Jump to page navigation: previous page [access key p]/next page [access key n]</a></div><header id="_mainnav"><div class="growth-inhibitor"><img src="static/images/logo.svg" alt="Logo" class="logo"/></div></header><div class="crumbs"><div class="growth-inhibitor"><a class="crumb" href="index.html">SUSE Edge Documentation</a><span> / </span><a class="crumb" href="id-quickstarts.html">Quickstarts</a><span> / </span><a class="crumb" href="id-demolab-setups.html">Demo/Lab Setups</a></div></div><main id="_content"><nav id="_side-toc-overall" class="side-toc"><div class="side-title">SUSE Edge Documentation</div><ol><li><a href="id-suse-edge-documentation.html" class=" "><span class="title-number"> </span><span class="title-name">SUSE Edge Documentation</span></a></li><li class="active"><a href="id-quickstarts.html" class="has-children you-are-here"><span class="title-number">I </span><span class="title-name">Quickstarts</span></a><ol><li><a href="id-demolab-setups.html" class=" you-are-here"><span class="title-number">1 </span><span class="title-name">Demo/Lab Setups</span></a></li><li><a href="id-standalone-clusters-with-edge-image-builder.html" class=" "><span class="title-number">2 </span><span class="title-name">Standalone Clusters with Edge Image Builder</span></a></li><li><a href="id-bmc-automated-deployments-with-metal3.html" class=" "><span class="title-number">3 </span><span class="title-name">BMC automated deployments with Metal<sup>3</sup></span></a></li><li><a href="id-remote-host-onboarding-with-elemental.html" class=" "><span class="title-number">4 </span><span class="title-name">Remote host onboarding with Elemental</span></a></li></ol></li><li><a href="id-components-used-2.html" class="has-children "><span class="title-number">II </span><span class="title-name">Components Used</span></a><ol><li><a href="id-elemental-2.html" class=" "><span class="title-number">5 </span><span class="title-name">Elemental</span></a></li><li><a href="id-fleet.html" class=" "><span class="title-number">6 </span><span class="title-name">Fleet</span></a></li><li><a href="id-longhorn.html" class=" "><span class="title-number">7 </span><span class="title-name">Longhorn</span></a></li><li><a href="id-metal.html" class=" "><span class="title-number">8 </span><span class="title-name">Metal³</span></a></li><li><a href="id-metallb.html" class=" "><span class="title-number">9 </span><span class="title-name">MetalLB</span></a></li><li><a href="id-neuvector.html" class=" "><span class="title-number">10 </span><span class="title-name">NeuVector</span></a></li><li><a href="id-rancher.html" class=" "><span class="title-number">11 </span><span class="title-name">Rancher</span></a></li><li><a href="id-sle-micro.html" class=" "><span class="title-number">12 </span><span class="title-name">SLE Micro</span></a></li><li><a href="id-k3s.html" class=" "><span class="title-number">13 </span><span class="title-name">K3s</span></a></li><li><a href="id-rke2.html" class=" "><span class="title-number">14 </span><span class="title-name">RKE2</span></a></li><li><a href="id-edge-image-builder.html" class=" "><span class="title-number">15 </span><span class="title-name">Edge Image Builder</span></a></li></ol></li><li><a href="id-third-party-integration.html" class="has-children "><span class="title-number">III </span><span class="title-name">Third Party Integration</span></a><ol><li><a href="id-create-a-package-rpm-or-container-image-using-obs-opensuse-build-service.html" class=" "><span class="title-number">16 </span><span class="title-name">Create a package (RPM or Container image) using OBS (openSUSE Build Service)</span></a></li><li><a href="id-using-the-linkerd-service-mesh.html" class=" "><span class="title-number">17 </span><span class="title-name">Using the Linkerd Service Mesh</span></a></li><li><a href="id-nats.html" class=" "><span class="title-number">18 </span><span class="title-name">NATS</span></a></li><li><a href="id-nvidia-gpus-on-sle-micro.html" class=" "><span class="title-number">19 </span><span class="title-name">NVIDIA GPU’s on SLE Micro</span></a></li></ol></li><li><a href="id-product-documentation.html" class="has-children "><span class="title-number">IV </span><span class="title-name">Product Documentation</span></a><ol><li><a href="atip.html" class=" "><span class="title-number">20 </span><span class="title-name">SUSE Adaptive Telco Infrastructure Platform (ATIP)</span></a></li></ol></li><li><a href="id-appendix.html" class="has-children "><span class="title-number">A </span><span class="title-name">Appendix</span></a><ol><li><a href="id-appendix.html#id-terminology" class=" "><span class="title-number"> </span><span class="title-name">Terminology</span></a></li></ol></li> </ol> </nav><button id="_open-side-toc-overall" title="Contents"> </button><article class="documentation"><button id="_unfold-side-toc-page">On this page</button><section class="chapter" id="id-demolab-setups" data-id-title="Demo/Lab Setups"><div class="titlepage"><div><div><div class="title-container"><h1 class="title"><span class="title-number-name"><span class="title-number">1 </span><span class="title-name">Demo/Lab Setups</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#">#</a></h1><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><section class="sect1" id="id-elemental-on-osx-on-apple-silicon-utm" data-id-title="Elemental on OSX on Apple Silicon (UTM)"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">1.1 </span><span class="title-name">Elemental on OSX on Apple Silicon (UTM)</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-elemental-on-osx-on-apple-silicon-utm">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><section class="sect2" id="id-elemental" data-id-title="Elemental"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">1.1.1 </span><span class="title-name">Elemental</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-elemental">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>Via the <a class="link" href="https://elemental.docs.rancher.com/" target="_blank">official docs</a>:</p><p>Elemental is a software stack enabling a centralized, full cloud-native OS management with Kubernetes.</p><p>The Elemental Stack consists of some packages on top of SLE Micro for Rancher:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>elemental-toolkit - includes a set of OS utilities to enable OS management via containers. Includes dracut modules, bootloader configuration, cloud-init style &gt; configuration services, etc.</p></li><li class="listitem"><p>elemental-operator - this connects to Rancher Manager and handles MachineRegistration and MachineInventory CRDs</p></li><li class="listitem"><p>elemental-register - this registers machines via machineRegistrations and installs them via elemental-cli</p></li><li class="listitem"><p>elemental-cli - this installs any elemental-toolkit based derivative. Basically an installer based on our A/B install and upgrade system</p></li><li class="listitem"><p>rancher-system-agent - runs on the installed system and gets instructions ("Plans") from Rancher Manager what to install and run on the system
Cluster Node OSes are built and maintained via container images through the Elemental CLI and they can be installed on new hosts using the Elemental UI plugin for &gt; Rancher Manager or the Elemental CLI.</p></li></ul></div><p>The Elemental Operator and the Rancher System Agent enable Rancher Manager to fully control Elemental clusters, from the installation and management of the OS on the &gt; Nodes to the provisioning of new K3s or RKE2 clusters in a centralized way.</p><section class="sect3" id="id-what-is-elemental-teal" data-id-title="What is Elemental Teal ?"><div class="titlepage"><div><div><div class="title-container"><h4 class="title"><span class="title-number-name"><span class="title-number">1.1.1.1 </span><span class="title-name">What is Elemental Teal ?</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-what-is-elemental-teal">#</a></h4><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>Elemental Teal is the combination of "SLE Micro for Rancher" with the Rancher Elemental stack.</p><p>SLE Micro for Rancher is a containerized and "stripped to the bones" operating system layer. At its core, it only requires grub2, dracut, a kernel, and systemd.</p><p>Its sole purpose is to run Kubernetes (k3s or RKE2), with everything controlled through Rancher Manager.</p><p>Elemental Teal is built in the openSUSE Build Service and available through the openSUSE Registry.</p></section></section><section class="sect2" id="id-prerequisites" data-id-title="Prerequisites"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">1.1.2 </span><span class="title-name">Prerequisites</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-prerequisites">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>Elemental is a Kubernetes thing, so it only requires a proper cluster up &amp; running. However, in order to provision real clusters and hosts, it requires to perform
some steps such as downloading and customizing an ISO (or an image file) and boot the ISO. This quickstart uses UTM to create a VM and a few steps to create a proper image to boot from.</p><p>The trick here is there is no ARM64 image yet, but just a Raspberry Pi one…​ so that’s the one we will use. It is not generic, but it works.</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>A Kubernetes cluster where Elemental is deployed. Hint, you can use <a class="link" href="https://suse-edge.github.io/quickstart/k3s-on-slemicro" target="_blank">the K3s on SLE Micro guide</a>.</p></li><li class="listitem"><p>Rancher server configured (server-url set). Hint: you can use <a class="link" href="https://ranchermanager.docs.rancher.com/v2.6/getting-started/quick-start-guides/deploy-rancher-manager/helm-cli" target="_blank">the official Rancher</a> docs or the <a class="link" href="https://github.com/suse-edge/misc/blob/main/slemicro/create_vm.sh" target="_blank">create_vm.sh</a> script for inspiration.</p></li><li class="listitem"><p>Helm</p></li><li class="listitem"><p>jq</p></li></ul></div></section><section class="sect2" id="id-elemental-ui-rancher-extension" data-id-title="Elemental UI Rancher extension"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">1.1.3 </span><span class="title-name">Elemental UI Rancher extension</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-elemental-ui-rancher-extension">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>This is an optional step to enable the Elemental UI extension in Rancher (see <a class="link" href="https://ranchermanager.docs.rancher.com/integrations-in-rancher/rancher-extensions" target="_blank">more about Rancher extensions</a>):</p><div class="verbatim-wrap highlight bash"><pre class="screen">helm repo add rancher-charts https://charts.rancher.io/
helm upgrade --create-namespace -n cattle-ui-plugin-system \
  --install ui-plugin-operator rancher-charts/ui-plugin-operator
helm upgrade --create-namespace -n cattle-ui-plugin-system \
  --install ui-plugin-operator-crd rancher-charts/ui-plugin-operator-crd

# Wait for the operator to be up
while ! kubectl wait --for condition=ready -n cattle-ui-plugin-system \
  $(kubectl get pods -n cattle-ui-plugin-system \
    -l app.kubernetes.io/instance=ui-plugin-operator -o name) \
    --timeout=10s; do sleep 2 ; done

# Deploy the elemental UI plugin
# NOTE: TABs and then spaces...
cat &lt;&lt;- FOO | kubectl apply -f -
apiVersion: catalog.cattle.io/v1
kind: UIPlugin
metadata:
  name: elemental
  namespace: cattle-ui-plugin-system
spec:
  plugin:
    endpoint: https://raw.githubusercontent.com/rancher/ui-plugin-charts/main/extensions/elemental/1.1.0
    name: elemental
    noCache: false
    version: 1.1.0
FOO

# Or
# helm repo add rancher-ui-plugins https://raw.githubusercontent.com/rancher/ui-plugin-charts/main
# helm upgrade --install elemental rancher-ui-plugins/elemental --namespace cattle-ui-plugin-system --create-namespace</pre></div><p>After a while, the plugin will be shown in the UI as:</p><div class="informalfigure"><div class="mediaobject"><a href="images/elemental-ui-plugin.png"><img src="images/elemental-ui-plugin.png" width="90%" alt="elemental ui plugin" title="elemental ui plugin"/></a></div></div></section><section class="sect2" id="id-elemental-operator" data-id-title="Elemental Operator"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">1.1.4 </span><span class="title-name">Elemental Operator</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-elemental-operator">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>Elemental is managed by an operator deployed via Helm as:</p><div class="verbatim-wrap highlight bash"><pre class="screen">helm upgrade --create-namespace -n cattle-elemental-system --install \
 --set image.imagePullPolicy=Always elemental-operator \
 oci://registry.opensuse.org/isv/rancher/elemental/dev/charts/rancher/elemental-operator-chart</pre></div><p><a class="link" href="https://github.com/rancher/elemental-operator/blob/main/chart/values.yaml" target="_blank">The values.yaml file have some variables interesting to see</a></p><p>After a few seconds you should see the operator pod appear on the <code class="literal">cattle-elemental-system</code> namespace:</p><div class="verbatim-wrap"><pre class="screen">kubectl get pods -n cattle-elemental-system
NAME                                  READY   STATUS    RESTARTS   AGE
elemental-operator-64f88fc695-b8qhn   1/1     Running   0          16s</pre></div></section><section class="sect2" id="id-kubernetes-resources" data-id-title="Kubernetes resources"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">1.1.5 </span><span class="title-name">Kubernetes resources</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-kubernetes-resources">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>Based on the <a class="link" href="https://elemental.docs.rancher.com/quickstart-cli" target="_blank">Elemental quickstart</a> guide, a few Kubernetes resources need to be created.</p><div id="id-1.3.3.2.6.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><p>It is out of the scope of this document to provide an explanation about the resources managed by Elemental, however the <a class="link" href="https://elemental.docs.rancher.com/machineregistration-reference" target="_blank">official documentation</a> explains all those in good detail.</p></div><div id="id-1.3.3.2.6.4" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg"/><div class="admon-title">Tip</div><p>In order to deploy more than one elemental machine, be sure that <code class="literal">spec.config.elemental.registration.emulated-tpm-seed=-1</code> is set in your <code class="literal">MachineRegistration</code> so the seed used for the TPM emulation is randomized per machine. Otherwise, you will get the same TPM Hash for all deployed machines and only the last one to be registered will be valid. See the official docs for <a class="link" href="http://elemental.docs.rancher.com/tpm" target="_blank">tpm</a> and <a class="link" href="http://elemental.docs.rancher.com/machineregistration-reference/#configelementalregistration" target="_blank">machineregistration</a> for more information.</p></div><div class="verbatim-wrap highlight yaml"><pre class="screen">cat &lt;&lt;- EOF | kubectl apply -f -
apiVersion: elemental.cattle.io/v1beta1
kind: MachineInventorySelectorTemplate
metadata:
  name: my-machine-selector
  namespace: fleet-default
spec:
  template:
    spec:
      selector:
        matchExpressions:
          - key: location
            operator: In
            values: [ 'europe' ]
EOF</pre></div><div class="verbatim-wrap highlight yaml"><pre class="screen">cat &lt;&lt;- EOF | kubectl apply -f -
kind: Cluster
apiVersion: provisioning.cattle.io/v1
metadata:
  name: my-cluster
  namespace: fleet-default
spec:
  rkeConfig:
    machineGlobalConfig:
      etcd-expose-metrics: false
      profile: null
    machinePools:
      - controlPlaneRole: true
        etcdRole: true
        machineConfigRef:
          apiVersion: elemental.cattle.io/v1beta1
          kind: MachineInventorySelectorTemplate
          name: my-machine-selector
        name: pool1
        quantity: 1
        unhealthyNodeTimeout: 0s
        workerRole: true
    machineSelectorConfig:
      - config:
          protect-kernel-defaults: false
    registries: {}
  kubernetesVersion: v1.24.8+k3s1
EOF</pre></div><div class="verbatim-wrap highlight yaml"><pre class="screen">cat &lt;&lt;- 'EOF' | kubectl apply -f -
apiVersion: elemental.cattle.io/v1beta1
kind: MachineRegistration
metadata:
  name: my-nodes
  namespace: fleet-default
spec:
  config:
    cloud-config:
      users:
        - name: root
          passwd: root
    elemental:
      install:
        reboot: true
        device: /dev/vda
        debug: true
        disable-boot-entry: true
      registration:
        emulate-tpm: true
        emulated-tpm-seed: -1
  machineInventoryLabels:
    manufacturer: "${System Information/Manufacturer}"
    productName: "${System Information/Product Name}"
    serialNumber: "${System Information/Serial Number}"
    machineUUID: "${System Information/UUID}"
EOF</pre></div><p>This creates a <code class="literal">MachineRegistration</code> object which will provide a unique URL which will be used with <code class="literal">elemental-register</code> to register the node during installation, so the operator can create a <code class="literal">MachineInventory</code> which will be using to bootstrap the node. See that the label has been see to match the selector here already, although it can always be added later to the <code class="literal">MachineInventory</code>.</p><div class="informalfigure"><div class="mediaobject"><a href="images/cluster-ui.png"><img src="images/cluster-ui.png" width="90%" alt="cluster ui" title="cluster ui"/></a></div></div><div id="id-1.3.3.2.6.10" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><p>At this point the x86_64 and ARM64 quickstart differs because for x86_64 there is a <code class="literal">SeedImage</code> object that needs to be created and that doesn’t exist for ARM64 (yet).</p></div></section><section class="sect2" id="id-preparing-the-installation-image" data-id-title="Preparing the installation image"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">1.1.6 </span><span class="title-name">Preparing the installation image</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-preparing-the-installation-image">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>Elemental’s support for Raspberry Pi is primarily for demonstration purposes at this point. Therefore the installation process is modelled similar to x86-64. You boot from a seed image (USB stick in this case) and install to a storage medium (SD-card for Raspberry Pi).</p><div id="id-1.3.3.2.7.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><p>The steps below should to be ran in a linux machine (<code class="literal">SLE Micro</code> for example).</p></div><p>First step is to download the <code class="literal">machineregistration</code> object that will instruct where to get the config for the node to be installed:</p><div class="verbatim-wrap highlight bash"><pre class="screen">curl -k $(kubectl get machineregistration -n fleet-default my-nodes \
 -o jsonpath="{.status.registrationURL}") -o livecd-cloud-config.yaml</pre></div><div class="informalfigure"><div class="mediaobject"><a href="images/registration-endpoint.png"><img src="images/registration-endpoint.png" width="90%" alt="registration endpoint" title="registration endpoint"/></a></div></div><p>Then, the <code class="literal">rpi.raw</code> image is downloaded and checked the integrity just to be safe:</p><div class="verbatim-wrap highlight bash"><pre class="screen">curl -Lk https://download.opensuse.org/repositories/isv:/Rancher:/Elemental:/Stable:/Teal53/images/rpi.raw -o rpi.raw
curl -Lk https://download.opensuse.org/repositories/isv:/Rancher:/Elemental:/Stable:/Teal53/images/rpi.raw.sha256 -o rpi.raw.sha256
sha256sum -c rpi.raw.sha256</pre></div><p>Finally, the <code class="literal">livecd-cloud-config.yaml</code> file is injected in the vanilla <code class="literal">rpi.raw</code> image:</p><div class="verbatim-wrap highlight bash"><pre class="screen">IMAGE=rpi.raw
DEST=$(mktemp -d)
SECTORSIZE=$(sfdisk -J ${IMAGE} | jq '.partitiontable.sectorsize')
DATAPARTITIONSTART=$(sfdisk -J ${IMAGE} | jq '.partitiontable.partitions[1].start')

mount -o rw,loop,offset=$((${SECTORSIZE}*${DATAPARTITIONSTART})) ${IMAGE} ${DEST}
mv livecd-cloud-config.yaml ${DEST}/livecd-cloud-config.yaml
umount ${DEST}</pre></div><div id="id-1.3.3.2.7.11" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><p>The <code class="literal">rpi.raw</code> image has two partitions. <code class="literal">RPI_BOOT</code> contains the boot loader files and <code class="literal">COS_LIVE</code> the Elemental files, where the <code class="literal">livecd-cloud-config.yaml</code> file needs to be copied.</p></div></section><section class="sect2" id="id-utm-vm" data-id-title="UTM VM"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">1.1.7 </span><span class="title-name">UTM VM</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-utm-vm">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>Then, a new UTM VM needs to be created and the <code class="literal">rpi.raw</code> file configured as USB.</p><div class="informalfigure"><div class="mediaobject"><a href="images/utm-welcome.png"><img src="images/utm-welcome.png" width="90%" alt="utm welcome" title="utm welcome"/></a></div></div><div class="informalfigure"><div class="mediaobject"><a href="images/utm-start.png"><img src="images/utm-start.png" width="90%" alt="utm start" title="utm start"/></a></div></div><div class="informalfigure"><div class="mediaobject"><a href="images/utm-os.png"><img src="images/utm-os.png" width="90%" alt="utm os" title="utm os"/></a></div></div><p>Map the raw file as an ISO and configure the hardware as you please:</p><div class="informalfigure"><div class="mediaobject"><a href="images/utm-hardware.png"><img src="images/utm-hardware.png" width="90%" alt="utm hardware" title="utm hardware"/></a></div></div><p>Set a proper name:</p><div class="informalfigure"><div class="mediaobject"><a href="images/utm-elemental-vm.png"><img src="images/utm-elemental-vm.png" width="90%" alt="utm elemental vm" title="utm elemental vm"/></a></div></div><p>Finally, it is needed to configure the raw disk as USB:</p><div class="informalfigure"><div class="mediaobject"><a href="images/usb-config-elemental.png"><img src="images/usb-config-elemental.png" width="90%" alt="usb config elemental" title="usb config elemental"/></a></div></div><div class="informalfigure"><div class="mediaobject"><a href="images/usb-config-order-elemental.png"><img src="images/usb-config-order-elemental.png" width="90%" alt="usb config order elemental" title="usb config order elemental"/></a></div></div><div id="id-1.3.3.2.8.13" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.svg"/><div class="admon-title">Important</div><p>The operating system disk device should be the first one, then the USB, so the USB will boot just once as a fallback.</p></div><p>After a while, a new <code class="literal">machineinventory</code> host will be present:</p><div class="verbatim-wrap highlight yaml"><pre class="screen">kubectl get machineinventory -n fleet-default m-ed0a3f46-d6f8-4737-9884-e3a898094994 -o yaml

apiVersion: elemental.cattle.io/v1beta1
kind: MachineInventory
metadata:
  annotations:
    elemental.cattle.io/registration-ip: 192.168.205.106
  creationTimestamp: "2023-05-03T14:04:56Z"
  generation: 1
  labels:
    machineUUID: ec49ff2a-e14f-42bf-8098-4162f14ee1f9
    manufacturer: QEMU
    productName: QEMU-Virtual-Machine
    serialNumber: Not-Specified
  name: m-ed0a3f46-d6f8-4737-9884-e3a898094994
  namespace: fleet-default
  resourceVersion: "15848"
  uid: 79608121-034d-4d64-8b48-6624607bbadd
spec:
  tpmHash: a2e5b231dac4e90151454e2ebc76a6b118f7d1b826b810d22868b2d09b38b7f7
status:
  conditions:
  - lastTransitionTime: "2023-05-03T14:07:45Z"
    message: plan successfully applied
    reason: PlanSuccessfullyApplied
    status: "True"
    type: Ready
  - lastTransitionTime: "2023-05-03T14:04:56Z"
    message: Waiting to be adopted
    reason: WaitingToBeAdopted
    status: "False"
    type: AdoptionReady
  plan:
    checksum: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
    secretRef:
      name: m-ed0a3f46-d6f8-4737-9884-e3a898094994
      namespace: fleet-default
    state: Applied</pre></div><p>Finally, labeling the <code class="literal">machineinventory</code> of the discovered new host will trigger the installation:</p><div class="verbatim-wrap highlight bash"><pre class="screen">kubectl -n fleet-default label machineinventory $(kubectl get \
 machineinventory -n fleet-default --no-headers \
 -o custom-columns=":metadata.name") location=europe</pre></div><div class="informalfigure"><div class="mediaobject"><a href="images/new-cluster.png"><img src="images/new-cluster.png" width="90%" alt="new cluster" title="new cluster"/></a></div></div><div class="verbatim-wrap"><pre class="screen">kubectl get cluster -n fleet-default
NAME         READY   KUBECONFIG
my-cluster   true    my-cluster-kubeconfig</pre></div><p>Profit!</p><div class="verbatim-wrap"><pre class="screen">kubectl get secret -n fleet-default my-cluster-kubeconfig \
  -o jsonpath='{.data.value}' | base64 -d &gt;&gt; ~/my-cluster-kubeconfig

KUBECONFIG=~/my-cluster-kubeconfig kubectl get nodes
NAME                                     STATUS   ROLES                              AGE     VERSION
m-ed0a3f46-d6f8-4737-9884-e3a898094994   Ready    control-plane,etcd,master,worker   6m25s   v1.24.8+k3s1

KUBECONFIG=~/my-cluster-kubeconfig kubectl get pods -A
NAMESPACE             NAME                                                              READY   STATUS      RESTARTS   AGE
cattle-fleet-system   fleet-agent-7ffcdff7c5-2rvvl                                      1/1     Running     0          2m47s
cattle-system         apply-system-agent-upgrader-on-m-ed0a3f46-d6f8-4737-9884-1jhpkx   0/1     Completed   0          2m1s
cattle-system         cattle-cluster-agent-684c4687c8-scgvb                             1/1     Running     0          61s
cattle-system         helm-operation-hjkcr                                              0/2     Completed   0          5m35s
cattle-system         rancher-webhook-85bb446df8-r8g6r                                  1/1     Running     0          5m22s
cattle-system         system-upgrade-controller-65bcf49944-rp2gr                        1/1     Running     0          2m47s
kube-system           coredns-7b5bbc6644-2zdlk                                          1/1     Running     0          6m20s
kube-system           helm-install-traefik-crd-ksm4q                                    0/1     Completed   0          61s
kube-system           helm-install-traefik-kg4qv                                        0/1     Completed   0          61s
kube-system           local-path-provisioner-687d6d7765-j54vp                           1/1     Running     0          6m20s
kube-system           metrics-server-84f8d4c4fc-6t6kc                                   1/1     Running     0          6m20s
kube-system           svclb-traefik-7ca8393f-gvdcc                                      2/2     Running     0          5m58s
kube-system           traefik-6b8f69d897-bwtgq                                          1/1     Running     0          5m58s</pre></div><div class="informalfigure"><div class="mediaobject"><a href="images/new-cluster-dashboard.png"><img src="images/new-cluster-dashboard.png" width="90%" alt="new cluster dashboard" title="new cluster dashboard"/></a></div></div></section></section><section class="sect1" id="id-k3s-on-sle-micro" data-id-title="K3s on SLE Micro"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">1.2 </span><span class="title-name">K3s on SLE Micro</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-k3s-on-sle-micro">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><section class="sect2" id="id-intro" data-id-title="Intro"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">1.2.1 </span><span class="title-name">Intro</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-intro">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p><a class="link" href="https://k3s.io/" target="_blank">K3s</a> is a highly available, certified Kubernetes distribution designed for production workloads in unattended, resource-constrained, remote locations or inside IoT appliances.</p><p>It is packaged as a single and small binary so installations and updates are fast and easy.</p><p>The installation procedure can be as simple as downloading the <code class="literal">k3s</code> binary and run it.
However, the preferred way is to use the install script as it creates and configures a service.</p><p>The script supports different installation parameters to customize K3s, including HA support, install control-plane nodes, dedicated etcd nodes, agents, etc.</p><p>Once installed, the parameters and flags can be modified, added or removed just by changing the systemd unit file or the config file and restarting the service. Neat!</p></section><section class="sect2" id="id-k3s-on-sle-micro-2" data-id-title="K3s on SLE Micro"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">1.2.2 </span><span class="title-name">K3s on SLE Micro</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-k3s-on-sle-micro-2">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>The installation scripts supports SLE Micro, it recognizes the underlying operating system, installs the <code class="literal">k3s-selinux</code> package using <code class="literal">transactional-updates</code> and creates the <code class="literal">k3s</code> or <code class="literal">k3s-agent</code> services.</p><div id="id-1.3.3.3.3.3" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg"/><div class="admon-title">Tip</div><p>On SLE Micro, the install script doesn’t start the <code class="literal">k3s</code> or <code class="literal">k3s-agent</code> service (ideally you should reboot the host once you run a transactional-update), but this can be override by using the <code class="literal">INSTALL_K3S_SKIP_START=false</code> environment variable.</p></div></section><section class="sect2" id="id-k3s-all-in-one" data-id-title="K3s all-in-one"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">1.2.3 </span><span class="title-name">K3s all-in-one</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-k3s-all-in-one">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>The simplest way to run K3s is an all-in-one server (not suited for production environments) is by running:</p><div class="verbatim-wrap highlight bash"><pre class="screen">curl -sfL https://get.k3s.io | sh -</pre></div><p>A few environment variables to tweak our installation can be used as well as:</p><div class="verbatim-wrap highlight bash"><pre class="screen">curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC="server \
 --cluster-init --write-kubeconfig-mode=644" K3S_TOKEN=foobar sh -</pre></div><p><a class="link" href="https://docs.k3s.io/installation/configuration#configuration-with-install-script" target="_blank">The settings can be specified either as environment variables, command line flags</a>, a <a class="link" href="https://docs.k3s.io/installation/configuration#configuration-file" target="_blank">configuration file</a>, or both, it is just a personal choice:</p><div class="verbatim-wrap highlight bash"><pre class="screen">curl -sfL https://get.k3s.io | sh -s - server --token foobar \
 --cluster-init --write-kubeconfig-mode=644</pre></div><div class="verbatim-wrap highlight yaml"><pre class="screen">write-kubeconfig-mode: "0644"
cluster-init: true
token: "foobar"</pre></div><p>In this example:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p><code class="literal">write-kubeconfig-mode</code> is self explanatory (the default is 0600)</p></li><li class="listitem"><p><code class="literal">cluster-init</code> enables clustering by deploying an embedded etcd database</p></li><li class="listitem"><p><code class="literal">token</code> a random token is generated to be able to add nodes to the cluster, specifying it at installation time makes things easier as it is known upfront</p></li></ul></div><p>The <a class="link" href="https://docs.k3s.io/cli" target="_blank">official</a> documentation explains all the flags in detail.</p></section><section class="sect2" id="id-adding-agents" data-id-title="Adding agents"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">1.2.4 </span><span class="title-name">Adding agents</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-adding-agents">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>Adding an agent is as simple as running the install script with a few parameters, including the URL of the cluster as:</p><div class="verbatim-wrap highlight bash"><pre class="screen">curl -sfL https://get.k3s.io | K3S_URL=https://myserver:6443 \
 K3S_TOKEN=foobar sh -</pre></div></section><section class="sect2" id="id-k3s-ha" data-id-title="K3s HA"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">1.2.5 </span><span class="title-name">K3s HA</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-k3s-ha">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>The easiest way to run a K3s HA cluster is by installing a first node using the <code class="literal">--cluster-init</code> flag and then, start adding nodes.</p><div class="variablelist"><dl class="variablelist"><dt id="id-1.3.3.3.6.3.1"><span class="term">First node</span></dt><dd><div class="verbatim-wrap highlight bash"><pre class="screen">curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC="server --cluster-init \
 --write-kubeconfig-mode=644" K3S_TOKEN=foobar sh -</pre></div></dd><dt id="id-1.3.3.3.6.3.2"><span class="term">Rest of the nodes</span></dt><dd><div class="verbatim-wrap highlight bash"><pre class="screen">curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC="server \
 --server https://myserver:6443 --write-kubeconfig-mode=644" \
 K3S_TOKEN=foobar sh -</pre></div></dd><dt id="id-1.3.3.3.6.3.3"><span class="term">Agent nodes</span></dt><dd><div class="verbatim-wrap highlight bash"><pre class="screen">curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC="agent \
 --server https://myserver:6443" K3S_TOKEN=foobar sh -</pre></div></dd></dl></div><p>This is what a cluster with 3 control-plane nodes and 2 agents looks like:</p><div class="verbatim-wrap"><pre class="screen">NAME   STATUS   ROLES                       AGE     VERSION        INTERNAL-IP       EXTERNAL-IP   OS-IMAGE                          KERNEL-VERSION                 CONTAINER-RUNTIME
cp01   Ready    control-plane,etcd,master   2m26s   v1.26.4+k3s1   192.168.205.99    &lt;none&gt;        SUSE Linux Enterprise Micro 5.4   5.14.21-150400.24.46-default   containerd://1.6.19-k3s1
cp02   Ready    control-plane,etcd,master   98s     v1.26.4+k3s1   192.168.205.100   &lt;none&gt;        SUSE Linux Enterprise Micro 5.4   5.14.21-150400.24.46-default   containerd://1.6.19-k3s1
cp03   Ready    control-plane,etcd,master   71s     v1.26.4+k3s1   192.168.205.101   &lt;none&gt;        SUSE Linux Enterprise Micro 5.4   5.14.21-150400.24.46-default   containerd://1.6.19-k3s1
w01    Ready    &lt;none&gt;                      63s     v1.26.4+k3s1   192.168.205.102   &lt;none&gt;        SUSE Linux Enterprise Micro 5.4   5.14.21-150400.24.46-default   containerd://1.6.19-k3s1
w02    Ready    &lt;none&gt;                      39s     v1.26.4+k3s1   192.168.205.103   &lt;none&gt;        SUSE Linux Enterprise Micro 5.4   5.14.21-150400.24.46-default   containerd://1.6.19-k3s1</pre></div></section><section class="sect2" id="id-k3s-api-ha" data-id-title="K3s API HA"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">1.2.6 </span><span class="title-name">K3s API HA</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-k3s-api-ha">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>The previous section lacks an important detail, the Kubernetes API is served by the 3 control-plane nodes, but the API certificate is generated just for the first node. If the first node is down, the clients needs their API endpoint to be tweaked to point to another node (i.e.- for <code class="literal">kubectl</code>, using the <code class="literal">-s</code> flag or modifying the <code class="literal">kubeconfig</code> file) and the certificate won’t be accepted as it doesn’t contain the IP/hostname of that other node (it can be forced to be ignored using <code class="literal">--insecure-skip-tls-verify=true</code> for <code class="literal">kubectl</code> but that’s not a good practice).</p><p>Ideally a mechanism to expose the K3s API in a high availability scenario is required. This usually means running a load balancer outside of the K3s cluster to serve and redirect the requests to the K3s API endpoints, so if one of the servers fail, the load balancer will re-route the requests to the other ones. This solves the HA problem but it adds complexity as it requires an external service, which sometimes is not available (typically in non-cloud environments such as baremetal deployments).</p><p>One approach can be to run a self-contained solution involving <a class="link" href="http://kube-vip.io/" target="_blank">kube-vip</a> to expose the <a class="link" href="https://kube-vip.io/docs/usage/k3s/" target="_blank">K3s API</a> over a virtual IP (optionally including a load balancer as well). This solves the HA problem but the certificate can still be a problem…​ but K3s got you covered. By using the <code class="literal">--tls-san</code> flag at K3s installation time, a list of IPs and/or hostnames can be provided for the certificate to be included as Subject Alternative Names, meaning the K3s API will be happily served from those IPs/hostnames, and if those are the ones being served by the VIP, the solution is now HA and certificate-proof! Let’s see it in more detail in the next section.</p><div id="id-1.3.3.3.7.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><p>kube-vip can be used also to expose Kubernetes services, but this is out of scope of this document.</p></div><section class="sect3" id="id-vip-reservation" data-id-title="VIP reservation"><div class="titlepage"><div><div><div class="title-container"><h4 class="title"><span class="title-number-name"><span class="title-number">1.2.6.1 </span><span class="title-name">VIP reservation</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-vip-reservation">#</a></h4><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>The VIP needs to be an IP available in the same subnet than the one where the control plane hosts are running (this is technically not true for the VIP itself but for <a class="link" href="https://kube-vip.io/docs/about/architecture/#technologies" target="_blank">load-balancing</a>).</p><div id="id-1.3.3.3.7.6.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><p>If you are using OSX to virtualize the SLE Micro OS where K3s is going to be installed, you can see the dhcp leases in the <code class="literal">/var/db/dhcpd_leases</code> file and the subnet range in the <code class="literal">/Library/Preferences/SystemConfiguration/com.apple.vmnet.plist</code> one. You can use a free IP in that range, but if you find a way to reserve an IP in that range, please open a GitHub issue or a pull request with instructions to do it!.</p></div></section><section class="sect3" id="id-k3s-installation-first-node" data-id-title="K3s installation - First node"><div class="titlepage"><div><div><div class="title-container"><h4 class="title"><span class="title-number-name"><span class="title-number">1.2.6.2 </span><span class="title-name">K3s installation - First node</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-k3s-installation-first-node">#</a></h4><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>The first step is to install K3s in HA and using the <code class="literal">--tls-san</code> flag as well. This flag can be repeated many times, so in this example will be used to add both the IP (<code class="literal">192.168.205.10</code> in this example) and the DNS name of the VIP (using <a class="link" href="https://sslip.io" target="_blank">sslip.io</a> as a poor’s man DNS):</p><div class="verbatim-wrap highlight bash"><pre class="screen">curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC="server --cluster-init \
 --write-kubeconfig-mode=644 --tls-san=192.168.205.10 \
 --tls-san=https://192.168.205.10.sslip.io" K3S_TOKEN=foobar sh -</pre></div><p>The rest of the nodes will be installed after kube-vip as the server URL for them to join the cluster will be the VIP.</p></section><section class="sect3" id="id-kube-vip-installation" data-id-title="Kube-vip installation"><div class="titlepage"><div><div><div class="title-container"><h4 class="title"><span class="title-number-name"><span class="title-number">1.2.6.3 </span><span class="title-name">Kube-vip installation</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-kube-vip-installation">#</a></h4><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>The official <a class="link" href="https://kube-vip.io/docs/usage/k3s/" target="_blank">kube-vip</a> documentation explains the steps in more detail, but essentially it means creating the required resource files for kube-vip to run (RBAC and a DaemonSet).</p><div id="id-1.3.3.3.7.8.3" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.svg"/><div class="admon-title">Important</div><p>IPVS modules must be loaded in order for the <a class="link" href="https://kube-vip.io/docs/about/architecture/#control-plane-load-balancing" target="_blank">load balancer feature</a> to work.
This is achieved by creating the following file:</p></div><div class="verbatim-wrap highlight bash"><pre class="screen">cat &lt;&lt;- EOF &gt; /etc/modules-load.d/ipvs.conf
ip_vs
ip_vs_rr
ip_vs_wrr
ip_vs_sh
nf_conntrack
EOF</pre></div><p>Configurations stored under <code class="literal">/etc/modules-load.d</code> will be automatically picked up and loaded on boot.
Loading them for the first time, however, can be achieved without rebooting by executing:</p><div class="verbatim-wrap highlight bash"><pre class="screen">for i in $(cat /etc/modules-load.d/ipvs.conf); do modprobe ${i}; done</pre></div><p>The Kubernetes resources can be created by leveraging <a class="link" href="https://docs.k3s.io/installation/packaged-components#auto-deploying-manifests-addons" target="_blank">K3s auto-deploy</a> feature
(aka. any manifest stored in a particular folder of the host <code class="literal">/var/lib/rancher/k3s/server/manifests</code> will be automatically deployed at the K3s service startup or when the file changes via something similar to <code class="literal">kubectl apply -f</code>).</p><div id="id-1.3.3.3.7.8.8" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><p>In this case, the <code class="literal">--services</code> flag for kube-vip won’t be used.</p></div><div class="verbatim-wrap highlight yaml"><pre class="screen">export VIP=192.168.205.10
cat &lt;&lt;- EOF &gt; /var/lib/rancher/k3s/server/manifests/kube-vip.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: kube-vip
  namespace: kube-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  annotations:
    rbac.authorization.kubernetes.io/autoupdate: "true"
  name: system:kube-vip-role
rules:
  - apiGroups: [""]
    resources: ["services", "services/status", "nodes", "endpoints"]
    verbs: ["list","get","watch", "update"]
  - apiGroups: ["coordination.k8s.io"]
    resources: ["leases"]
    verbs: ["list", "get", "watch", "update", "create"]
---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: system:kube-vip-binding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: system:kube-vip-role
subjects:
- kind: ServiceAccount
  name: kube-vip
  namespace: kube-system
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  labels:
    app.kubernetes.io/name: kube-vip-ds
    app.kubernetes.io/version: v0.5.12
  name: kube-vip-ds
  namespace: kube-system
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: kube-vip-ds
  template:
    metadata:
      labels:
        app.kubernetes.io/name: kube-vip-ds
        app.kubernetes.io/version: v0.5.12
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: node-role.kubernetes.io/master
                operator: Exists
            - matchExpressions:
              - key: node-role.kubernetes.io/control-plane
                operator: Exists
      containers:
      - args:
        - manager
        env:
        - name: vip_arp
          value: "true"
        - name: port
          value: "6443"
        - name: vip_interface
          value: eth0
        - name: vip_cidr
          value: "32"
        - name: cp_enable
          value: "true"
        - name: cp_namespace
          value: kube-system
        - name: vip_ddns
          value: "false"
        - name: vip_leaderelection
          value: "true"
        - name: vip_leaseduration
          value: "5"
        - name: vip_renewdeadline
          value: "3"
        - name: vip_retryperiod
          value: "1"
        - name: address
          value: ${VIP}
        - name: prometheus_server
          value: :2112
        - name: lb_enable
          value: "true"
        image: ghcr.io/kube-vip/kube-vip:v0.5.12
        imagePullPolicy: Always
        name: kube-vip
        securityContext:
          capabilities:
            add:
            - NET_ADMIN
            - NET_RAW
      hostNetwork: true
      serviceAccountName: kube-vip
      tolerations:
      - effect: NoSchedule
        operator: Exists
      - effect: NoExecute
        operator: Exists
EOF</pre></div></section><section class="sect3" id="id-k3s-installation-control-plane-nodes" data-id-title="K3s installation - Control-plane nodes"><div class="titlepage"><div><div><div class="title-container"><h4 class="title"><span class="title-number-name"><span class="title-number">1.2.6.4 </span><span class="title-name">K3s installation - Control-plane nodes</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-k3s-installation-control-plane-nodes">#</a></h4><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>Once kube-vip is in place, the rest of the control-plane nodes can be added to the cluster by pointing them to the VIP as:</p><div class="verbatim-wrap highlight bash"><pre class="screen">export VIP=192.168.205.10
curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC="server \
 --server https://${VIP}:6443 --write-kubeconfig-mode=644" K3S_TOKEN=foobar sh -</pre></div><div id="id-1.3.3.3.7.9.4" class="admonition important normal"><img class="symbol" alt="Important" title="Important" src="static/images/icon-important.svg"/><div class="admon-title">Important</div><p>For a real HA scenario, it is required for <code class="literal">etcd</code> to have an odd number of nodes, so it would be required to add two more control plane nodes.</p></div><p>After a while, the nodes will join the cluster successfully and an HA cluster will be ready.</p></section><section class="sect3" id="id-kubeconfig-tweaks" data-id-title="Kubeconfig tweaks"><div class="titlepage"><div><div><div class="title-container"><h4 class="title"><span class="title-number-name"><span class="title-number">1.2.6.5 </span><span class="title-name">Kubeconfig tweaks</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-kubeconfig-tweaks">#</a></h4><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>The kubeconfig file that is generated as part of the installation has localhost as the Kubernetes API endpoint, so in order to use it from outside, it needs to be changed to the VIP as:</p><div class="variablelist"><dl class="variablelist tabs"><dt id="id-1.3.3.3.7.10.3.1"><span class="term">SUSE</span></dt><dd><div class="verbatim-wrap highlight bash"><pre class="screen">scp 192.168.205.10:/etc/rancher/k3s/k3s.yaml ~/.kube/config &amp;&amp; \
 sed -i 's/127.0.0.1/192.168.205.10/g' ~/.kube/config &amp;&amp; \
 chmod 600 ~/.kube/config</pre></div></dd><dt id="id-1.3.3.3.7.10.3.2"><span class="term">MacOS</span></dt><dd><div class="verbatim-wrap highlight bash"><pre class="screen">scp 192.168.205.10:/etc/rancher/k3s/k3s.yaml ~/.kube/config &amp;&amp; \
 sed -i '' 's/127.0.0.1/192.168.205.10/g' ~/.kube/config \
 &amp;&amp; chmod 600 ~/.kube/config</pre></div></dd></dl></div></section><section class="sect3" id="id-k3s-installation-adding-agents" data-id-title="K3s installation - adding agents"><div class="titlepage"><div><div><div class="title-container"><h4 class="title"><span class="title-number-name"><span class="title-number">1.2.6.6 </span><span class="title-name">K3s installation - adding agents</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-k3s-installation-adding-agents">#</a></h4><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>Agents can be added as usual, pointing to the VIP address as:</p><div class="verbatim-wrap highlight bash"><pre class="screen">export VIP=192.168.205.10
curl -sfL https://get.k3s.io | INSTALL_K3S_EXEC="agent \
 --server https://${VIP}:6443" K3S_TOKEN=foobar sh -</pre></div></section><section class="sect3" id="id-final-picture" data-id-title="Final picture"><div class="titlepage"><div><div><div class="title-container"><h4 class="title"><span class="title-number-name"><span class="title-number">1.2.6.7 </span><span class="title-name">Final picture</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-final-picture">#</a></h4><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><div class="verbatim-wrap"><pre class="screen">kubectl get nodes -o jsonpath="{.items[*].status.addresses[?(@.type=='InternalIP')].address}"
192.168.205.69 192.168.205.70 192.168.205.71 192.168.205.72 192.168.205.73%

kubectl cluster-info
Kubernetes control plane is running at https://192.168.205.10:6443</pre></div><p>As you can see, the control plane IP is the VIP and the nodes have their own IP. Sweet!</p></section></section><section class="sect2" id="id-k3s-tips" data-id-title="K3s tips"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">1.2.7 </span><span class="title-name">K3s tips</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-k3s-tips">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><section class="sect3" id="id-access-traefik-dashboard" data-id-title="Access Traefik dashboard"><div class="titlepage"><div><div><div class="title-container"><h4 class="title"><span class="title-number-name"><span class="title-number">1.2.7.1 </span><span class="title-name">Access Traefik dashboard</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-access-traefik-dashboard">#</a></h4><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><div class="verbatim-wrap highlight bash"><pre class="screen">kubectl port-forward $(kubectl get pods \
 --selector "app.kubernetes.io/name=traefik" -o=name -n kube-system) \
 -n kube-system 9000:9000</pre></div><p>Then, browse <a class="link" href="http://localhost:9000/dashboard" target="_blank">http://localhost:9000/dashboard</a> to observe the Traefik dashboard:</p><div class="informalfigure"><div class="mediaobject"><a href="images/traefikdashboard.png"><img src="images/traefikdashboard.png" width="90%" alt="traefikdashboard" title="traefikdashboard"/></a></div></div></section></section></section><section class="sect1" id="id-sle-micro-on-osx-on-apple-silicon-utm" data-id-title="SLE Micro on OSX on Apple Silicon (UTM)"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">1.3 </span><span class="title-name">SLE Micro on OSX on Apple Silicon (UTM)</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-sle-micro-on-osx-on-apple-silicon-utm">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><section class="sect2" id="id-osx-virtualization" data-id-title="OSX Virtualization"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">1.3.1 </span><span class="title-name">OSX Virtualization</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-osx-virtualization">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>Virtualization of Linux hosts on OSX can be achieved with various tools.
There are commercial products such as VMWare Fusion or Parallels Desktop
as well as open-source projects such as VirtualBox, UTM or Lima.</p><p>UTM is an OSX application that uses QEMU under the hood and offers a GUI
to manage the VM lifecycle. It supports Apple silicon CPUs, and it can
use native OSX virtualization (Virtualization.framework) as well. It
also has a scripting interface via <a class="link" href="https://docs.getutm.app/scripting/scripting/" target="_blank">Apple
Script</a> to automate some
processes and a proper CLI (utmctl) is on the works.</p><p>Lima is based on QEMU (experimental support for
Virtualization.framework) as well and it launches Linux virtual machines
with automatic file sharing and port forwarding (like WSL2), and
containerd. Lima is expected to be used on macOS hosts, but can be used
on Linux hosts as well. Lima has a proper CLI tool (limactl) and the
best part is VMs can be defined in yaml files, so you can even deploy
K8s clusters with just a single command
(see <a class="link" href="https://github.com/lima-vm/lima/blob/master/examples/k8s.yaml" target="_blank">https://github.com/lima-vm/lima/blob/master/examples/k8s.yaml</a>)</p><div id="id-1.3.3.4.2.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><p>Rancher desktop is <a class="link" href="https://github.com/rancher-sandbox/rancher-desktop/issues/3702" target="_blank">based on Lima</a></p></div><p>However, Lima doesn’t support SLE Micro
(<a class="link" href="https://github.com/lima-vm/lima/issues/1456" target="_blank">yet</a>) as Lima customizes
the VM at boot to install some packages and services and SLE Micro uses a
different approach to those things (for example as it is immutable, it
requires installing packages using ignition/combustion)</p></section><section class="sect2" id="id-sle-micro-installation-automation-iso-vs-image" data-id-title="SLE Micro installation automation: ISO vs Image"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">1.3.2 </span><span class="title-name">SLE Micro installation automation: ISO vs Image</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-sle-micro-installation-automation-iso-vs-image">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>SLE Micro can be installed traditionally using an ISO file that boots
once and using click-ops you can customize it as you wish
(see <a class="link" href="https://documentation.suse.com/sle-micro/5.3/single-html/SLE-Micro-deployment/#cha-install" target="_blank">https://documentation.suse.com/sle-micro/5.3/single-html/SLE-Micro-deployment/#cha-install</a>)
but that won’t be useful.</p><p>ISO installation can be customized using boot parameters
(see <a class="link" href="https://documentation.suse.com/sle-micro/5.3/single-html/SLE-Micro-deployment/#sec-boot-parameters-list" target="_blank">https://documentation.suse.com/sle-micro/5.3/single-html/SLE-Micro-deployment/#sec-boot-parameters-list</a>)
but those don’t cover all the options. However, ISO based installation
supports using AutoYaST (see <a class="link" href="https://documentation.suse.com/sle-micro/5.3/single-html/SLE-Micro-autoyast/" target="_blank">https://documentation.suse.com/sle-micro/5.3/single-html/SLE-Micro-autoyast/</a>)
to automate the installation process.</p><p>SLE Micro can be also deployed using pre-built images. Currently, there
are two types of images available: raw disk images and selfinstall ISOs.</p><p>SLE Micro raw images are delivered for the AMD64/Intel 64 architecture,
IBM Z ZSeries and also AArch64, however the selfinstall images are
currently delivered only for the AMD64/Intel 64 architecture. The
pre-built images (both selfinstall ISOs and raw disk images) are
intended to be configured on the first boot by using either Ignition or
Combustion.</p><p><span class="emphasis"><em>To summarize</em></span>, the two ways as of today to deploy SLE Micro on Aarch64
on an automated fashion would be using the ISO + AutoYaST or raw
images + Ignition/Combustion.</p></section><section class="sect2" id="id-ignition-vs-butane-vs-combustion" data-id-title="Ignition vs Butane vs Combustion"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">1.3.3 </span><span class="title-name">Ignition vs Butane vs Combustion</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-ignition-vs-butane-vs-combustion">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><div class="variablelist"><dl class="variablelist"><dt id="id-1.3.3.4.4.2.1"><span class="term">Ignition</span></dt><dd><p>is a provisioning tool that enables you to configure a
system according to your specification on the first boot. When the
system is booted for the first time, Ignition is loaded as part of an
initramfs and searches for a configuration file within a specific
directory (on a USB flash disk, or you can provide a URL). All changes
are performed before the kernel switches from the temporal file system
to the real root file system (before the switch_root command is issued).
Ignition uses a configuration file in the JSON format. The file is
called config.ign. SLE Micro supports
<a class="link" href="https://coreos.github.io/ignition/configuration-v3_3/" target="_blank">Ignition config spec 3.3.0</a>
(see
<a class="link" href="https://documentation.suse.com/sle-micro/5.3/single-html/SLE-Micro-deployment/#sec-ignition-configuration" target="_blank">https://documentation.suse.com/sle-micro/5.3/single-html/SLE-Micro-deployment/#sec-ignition-configuration</a>
for more information).</p><p>Ignition files can be complex to generate manually (specially for the
file permissions syntax in hex or multiline things) so you can use
<a class="link" href="https://opensuse.github.io/fuel-ignition/" target="_blank">opensuse.github.io/fuel-ignition</a>
to help you generate a basic one.</p></dd><dt id="id-1.3.3.4.4.2.2"><span class="term">Butane</span></dt><dd><p>is a more human readable (and writable) configuration syntax
based on yaml that can be translated to Ignition easily with the <a class="link" href="https://coreos.github.io/butane/" target="_blank">butane
CLI</a> as Butane is not consumable by
Ignition.</p></dd><dt id="id-1.3.3.4.4.2.3"><span class="term">Combustion</span></dt><dd><p>is a dracut module that enables you to configure your
system on its first boot. Combustion reads a provided file called <code class="literal">script</code>
and executes commands in it and thus performs changes to the file
system. You can use Combustion to change the default partitions, set
users' passwords, create files, install packages, etc.</p><p>The Combustion dracut module is invoked after the <code class="literal">ignition.firstboot</code>
argument is passed to the kernel command line. Combustion then reads the
configuration from script. Combustion tries to configure the network, if
the network flag has been found in script. After <code class="literal">/sysroot</code> is mounted,
Combustion tries to activate all mount points in <code class="literal">/etc/fstab</code> and then
call <code class="literal">transactional-update</code> to apply other changes (like setting root
password or installing packages).
See <a class="link" href="https://documentation.suse.com/sle-micro/5.3/single-html/SLE-Micro-deployment/#sec-combustion-script" target="_blank">https://documentation.suse.com/sle-micro/5.3/single-html/SLE-Micro-deployment/#sec-combustion-script</a>
for more information.</p></dd></dl></div></section><section class="sect2" id="id-ignitioncombustion-and-utm" data-id-title="Ignition/Combustion and UTM"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">1.3.4 </span><span class="title-name">Ignition/Combustion and UTM</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-ignitioncombustion-and-utm">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>Ignition and Combustion are intended to automate the deployment of SLE
Micro systems. To use them with UTM there are a couple of alternatives:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Use the QEMU <code class="literal">fw_cfg</code> flag as <code class="literal">-fw_cfg name=opt/org.opensuse.combustion/script,file=/var/combustion-script</code>
for combustion or <code class="literal">-fw_cfg name=opt/com.coreos/config,file=PATH_TO_config.ign</code> for ignition</p></li><li class="listitem"><p>Create a raw disk or ISO file to host the Ignition or Combustion (or
both) files.</p></li></ul></div><p>For Ignition, the configuration file <code class="literal">config.ign</code> must reside in the
<code class="literal">ignition</code> subdirectory on the configuration media labeled <code class="literal">ignition</code>. The
directory structure must look as follows:</p><div class="verbatim-wrap"><pre class="screen">&lt;root directory&gt;
└── ignition
    └── config.ign</pre></div><p>For Combustion, the configuration device needs to be named <code class="literal">combustion</code>, a
specific directory structure in that configuration medium needs to be
created and include a configuration file named <code class="literal">script</code>. In the root
directory of the configuration medium, create a directory called
<code class="literal">combustion</code> and place the <code class="literal">script</code> into this directory along with other
files—​SSH key, configuration files, etc. The directory structure then
should look as follows:</p><div class="verbatim-wrap"><pre class="screen">&lt;root directory&gt;
└── combustion
    └── script
    └── other files</pre></div><p>Combustion can be used along with Ignition. If you intend to do so,
label your configuration medium <code class="literal">ignition</code> and include the <code class="literal">ignition</code>
directory with the <code class="literal">config.ign</code> to your directory structure as shown
below:</p><div class="verbatim-wrap"><pre class="screen">&lt;root directory&gt;
└── combustion
    └── script
    └── other files
└── ignition
    └── config.ign</pre></div><p>In this scenario, Ignition runs before Combustion.</p></section><section class="sect2" id="id-image-based-process-step-by-step" data-id-title="Image-based process step by step"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">1.3.5 </span><span class="title-name">Image-based process step by step</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-image-based-process-step-by-step">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><div id="id-1.3.3.4.6.2" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg"/><div class="admon-title">Tip</div><p>There is a helper script that automates all the steps included <a class="link" href="https://github.com/suse-edge/misc/blob/main/slemicro/create_vm.sh" target="_blank">here</a>.</p></div><section class="sect3" id="id-prerequisites-2" data-id-title="Prerequisites"><div class="titlepage"><div><div><div class="title-container"><h4 class="title"><span class="title-number-name"><span class="title-number">1.3.5.1 </span><span class="title-name">Prerequisites</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-prerequisites-2">#</a></h4><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>SLE Micro raw image</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Download the raw image file from the SUSE website at <a class="link" href="https://www.suse.com/download/sle-micro/" target="_blank">https://www.suse.com/download/sle-micro/</a></p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Select ARM architecture</p></li><li class="listitem"><p>Look for the raw file (I.e.- <code class="literal">SLE-Micro.aarch64-5.3.0-Default-GM.raw.xz</code>)</p><div id="id-1.3.3.4.6.3.2.1.2.1.2.2.2" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><p>You need to have a valid user on the SUSE site to be able to download the
file.</p></div></li></ul></div></li></ul></div></li><li class="listitem"><p>Access to <a class="link" href="https://scc.suse.com/" target="_blank">SCC.suse.com</a> to generate a registration code</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Search for <code class="literal">SUSE Linux Enterprise Micro</code> via the <code class="literal">Products</code> menu, select the arch/version then copy and manually activate the registration code</p></li></ul></div></li><li class="listitem"><p>Butane, qemu and cdrtools installed (using brew for example)</p><div class="verbatim-wrap highlight bash"><pre class="screen">brew install butane cdrtools qemu</pre></div></li><li class="listitem"><p>UTM installed (using brew for example)</p><div class="verbatim-wrap highlight bash"><pre class="screen">brew install --cask utm</pre></div></li></ul></div><div id="id-1.3.3.4.6.3.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><p>If using the previous script, it is required to install UTM
4.2.2 at least as it includes the proper support for the automation.</p></div></section><section class="sect3" id="id-image-preparation" data-id-title="Image preparation"><div class="titlepage"><div><div><div class="title-container"><h4 class="title"><span class="title-number-name"><span class="title-number">1.3.5.2 </span><span class="title-name">Image preparation</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-image-preparation">#</a></h4><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Uncompress the SLE Micro image</p><div class="verbatim-wrap highlight bash"><pre class="screen">xz -d ~/Downloads/SLE-Micro.*-Default-GM.raw.xz</pre></div></li><li class="listitem"><p>Move the file to a proper location and rename it to fit the VM
hostname</p><div class="verbatim-wrap highlight bash"><pre class="screen">cp ~/Downloads/SLE-Micro.*-Default-GM.raw ~/VMs/slemicro.raw</pre></div></li><li class="listitem"><p>Resize the image file. In this example, to 30G</p><div class="verbatim-wrap highlight bash"><pre class="screen">qemu-img resize -f raw ~/VMs/slemicro.raw 30G &gt; /dev/null</pre></div></li></ul></div></section><section class="sect3" id="id-ignition-combustion-files" data-id-title="Ignition Combustion files"><div class="titlepage"><div><div><div class="title-container"><h4 class="title"><span class="title-number-name"><span class="title-number">1.3.5.3 </span><span class="title-name">Ignition &amp; Combustion files</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-ignition-combustion-files">#</a></h4><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>To automate the installation, we will leverage Butane, Ignition and
Combustion as explained before:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Create a temporary folder to store the assets</p><div class="verbatim-wrap highlight bash"><pre class="screen">TMPDIR=$(mktemp -d)</pre></div></li><li class="listitem"><p>Create the required folders for ignition and combustion</p><div class="verbatim-wrap highlight bash"><pre class="screen">mkdir -p ${TMPDIR}/{combustion,ignition}</pre></div></li><li class="listitem"><p>Create a <code class="literal">config.fcc</code> butane config file as required. See the
following example to set a <code class="literal">root</code> password for the root user, and to
configure the hostname to be "slemicro"'</p><div class="verbatim-wrap highlight yaml"><pre class="screen">cat &lt;&lt; 'EOF' &gt; ${TMPDIR}/config.fcc
variant: fcos
version: 1.4.0
storage:
  files:
    - path: /etc/hostname
      mode: 0644
      overwrite: true
      contents:
        inline: "slemicro"
passwd:
  users:
   - name: root
     password_hash: "$y$j9T$/t4THH10B7esLiIVBROsE.$G1lyxfy/MoFVOrfXSnWAUq70Tf3mjfZBIe18koGOuXB"
EOF</pre></div></li><li class="listitem"><p>Create a script combustion file as required. See the following
example to register the SLE Micro instance to SUSE’s SCC (use your
own email/regcode) and to create a <code class="literal">/etc/issue.d/combustion</code> file</p><div class="verbatim-wrap highlight bash"><pre class="screen">cat &lt;&lt; EOF &gt; ${TMPDIR}/combustion/script
#!/bin/bash
# combustion: network

# Redirect output to the console
exec &gt; &gt;(exec tee -a /dev/tty0) 2&gt;&amp;1

# Set hostname at combustion phase for SUSEConnect
hostname slemicro

# Registration
if ! which SUSEConnect &gt; /dev/null 2&gt;&amp;1; then
    zypper --non-interactive install suseconnect-ng
fi

SUSEConnect --email foobar@suse.com --url https://scc.suse.com --regcode YOURCODE

# Leave a marker
echo "Configured with combustion" &gt; /etc/issue.d/combustion
EOF</pre></div></li><li class="listitem"><p>Convert the butane config to ignition</p><div class="verbatim-wrap highlight bash"><pre class="screen">butane -p -o ${TMPDIR}/ignition/config.ign ${TMPDIR}/config.fcc</pre></div></li><li class="listitem"><p>Create an ISO file. It is requried for both ignition and combustion
to work that the ISO is labeled as <code class="literal">ignition</code> (hence the -V
parameter)</p><div class="verbatim-wrap highlight bash"><pre class="screen">mkisofs -full-iso9660-filenames -o ignition-and-combustion.iso \
 -V ignition ${TMPDIR}</pre></div></li><li class="listitem"><p><span class="strong"><strong>Optional:</strong></span> Remove the temporary folder</p><div class="verbatim-wrap highlight bash"><pre class="screen">rm -rf ${TMPDIR}</pre></div></li></ul></div></section><section class="sect3" id="id-vm-creation" data-id-title="VM Creation"><div class="titlepage"><div><div><div class="title-container"><h4 class="title"><span class="title-number-name"><span class="title-number">1.3.5.4 </span><span class="title-name">VM Creation</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-vm-creation">#</a></h4><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>Now it is time to finally use UTM to boot the VM</p><div class="informalfigure"><div class="mediaobject"><a href="images/utm-welcome.png"><img src="images/utm-welcome.png" width="90%" alt="utm welcome" title="utm welcome"/></a></div></div><p>Create a New Virtual Machine using Virtualization</p><div class="informalfigure"><div class="mediaobject"><a href="images/utm-start.png"><img src="images/utm-start.png" width="90%" alt="utm start" title="utm start"/></a></div></div><p>Select "Other"</p><div class="informalfigure"><div class="mediaobject"><a href="images/utm-os.png"><img src="images/utm-os.png" width="90%" alt="utm os" title="utm os"/></a></div></div><p>Enable the "Skip ISO boot" option as we will use the raw disk directly</p><div class="informalfigure"><div class="mediaobject"><a href="images/utm-other.png"><img src="images/utm-other.png" width="90%" alt="utm other" title="utm other"/></a></div></div><p>Select the required CPU/RAM:</p><div class="informalfigure"><div class="mediaobject"><a href="images/utm-hardware.png"><img src="images/utm-hardware.png" width="90%" alt="utm hardware" title="utm hardware"/></a></div></div><p>Accept the storage size as it is, it will be deleted before booting it</p><div class="informalfigure"><div class="mediaobject"><a href="images/utm-storage.png"><img src="images/utm-storage.png" width="90%" alt="utm storage" title="utm storage"/></a></div></div><p>Skip the Shared Directory</p><div class="informalfigure"><div class="mediaobject"><a href="images/utm-shared-directory.png"><img src="images/utm-shared-directory.png" width="90%" alt="utm shared directory" title="utm shared directory"/></a></div></div><p>Edit the VM name and enable the "Open VM Settings" toggle to customize
it further:</p><div class="informalfigure"><div class="mediaobject"><a href="images/utm-summary.png"><img src="images/utm-summary.png" width="90%" alt="utm summary" title="utm summary"/></a></div></div><p>Delete the VirtIO Drive</p><div class="informalfigure"><div class="mediaobject"><a href="images/utm-delete-virtio.png"><img src="images/utm-delete-virtio.png" width="90%" alt="utm delete virtio" title="utm delete virtio"/></a></div></div><p>Add a new Drive and select "Import"</p><div class="informalfigure"><div class="mediaobject"><a href="images/utm-import-raw.png"><img src="images/utm-import-raw.png" width="90%" alt="utm import raw" title="utm import raw"/></a></div></div><p>Select the raw image file (~/VMs/slemicro.raw in this case)</p><div class="informalfigure"><div class="mediaobject"><a href="images/utm-select-image.png"><img src="images/utm-select-image.png" width="90%" alt="utm select image" title="utm select image"/></a></div></div><p>Repeat the last two steps to add the ignition-and-combustion.iso file</p><div class="informalfigure"><div class="mediaobject"><a href="images/utm-select-iso.png"><img src="images/utm-select-iso.png" width="90%" alt="utm select iso" title="utm select iso"/></a></div></div><p>Configure the ISO as Read Only and "CD/DVD (ISO) Image"</p><div class="informalfigure"><div class="mediaobject"><a href="images/utm-configure-iso.png"><img src="images/utm-configure-iso.png" width="90%" alt="utm configure iso" title="utm configure iso"/></a></div></div><p>Finally, boot the VM.</p><p>After a couple of seconds, the VM will boot up and will configure itself
using the ignition and combustion scripts, including registering itself
to SCC</p><div class="informalfigure"><div class="mediaobject"><a href="images/slemicro-firstboot.png"><img src="images/slemicro-firstboot.png" width="90%" alt="slemicro firstboot" title="slemicro firstboot"/></a></div></div><div class="informalfigure"><div class="mediaobject"><a href="images/scc-systems.png"><img src="images/scc-systems.png" width="90%" alt="scc systems" title="scc systems"/></a></div></div><div id="id-1.3.3.4.6.6.32" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg"/><div class="admon-title">Tip</div><p>In case the VM doesn’t get network connectivity, try
<a class="link" href="https://github.com/utmapp/UTM/discussions/3530#discussioncomment-5072113" target="_blank">https://github.com/utmapp/UTM/discussions/3530#discussioncomment-5072113</a></p></div><div id="id-1.3.3.4.6.6.33" class="admonition tip normal"><img class="symbol" alt="Tip" title="Tip" src="static/images/icon-tip.svg"/><div class="admon-title">Tip</div><p>Once the VM is running, you can access via SSH via its IP as <code class="literal">ssh root@&lt;ip&gt;</code></p></div></section></section><section class="sect2" id="id-iso-process-tbd" data-id-title="ISO Process (TBD)"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">1.3.6 </span><span class="title-name">ISO Process (TBD)</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-iso-process-tbd">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Download the ISO file</p></li><li class="listitem"><p>Create a new VM on UTM using the ISO file</p></li><li class="listitem"><p>Create the autoyast answer file</p></li><li class="listitem"><p>Use the AutoYaST boot parameter to map to the answer file</p></li><li class="listitem"><p>Boot the VM</p></li><li class="listitem"><p>Profit!</p></li></ul></div></section></section><section class="sect1" id="id-sle-micro-on-x86_64-on-libvirt-virt-install" data-id-title="SLE Micro on X86_64 on libvirt (virt-install)"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">1.4 </span><span class="title-name">SLE Micro on X86_64 on libvirt (virt-install)</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-sle-micro-on-x86_64-on-libvirt-virt-install">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><section class="sect2" id="id-libvirt" data-id-title="Libvirt"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">1.4.1 </span><span class="title-name">Libvirt</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-libvirt">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><section class="sect3" id="id-libvirtd" data-id-title="libvirtd"><div class="titlepage"><div><div><div class="title-container"><h4 class="title"><span class="title-number-name"><span class="title-number">1.4.1.1 </span><span class="title-name">libvirtd</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-libvirtd">#</a></h4><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>The libvirtd program is the server side daemon component of the libvirt virtualization management system.
This daemon runs on host servers and performs required management tasks for virtualized guests. This includes activities such as starting, stopping and migrating guests between host servers, configuring and manipulating networking, and managing storage for use by guests.
The libvirt client libraries and utilities connect to this daemon to issue tasks and collect information about the configuration and resources of the host system and guests.
(see <a class="link" href="https://libvirt.org/manpages/libvirtd.html" target="_blank">https://libvirt.org/manpages/libvirtd.html</a>)</p></section><section class="sect3" id="id-virt-install" data-id-title="virt-install"><div class="titlepage"><div><div><div class="title-container"><h4 class="title"><span class="title-number-name"><span class="title-number">1.4.1.2 </span><span class="title-name">virt-install</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-virt-install">#</a></h4><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p><code class="literal">virt-install</code> is a command line tool for creating new KVM , Xen, or Linux container guests using the "libvirt" hypervisor management library. See the EXAMPLES section at the end of this document to quickly get started.
<code class="literal">virt-install</code> tool supports both text based &amp; graphical installations, using VNC or SDL graphics, or a text serial console. The guest can be configured to use one or more virtual disks, network interfaces, audio devices, physical USB or PCI devices, among others.
The installation media can be held locally or remotely on NFS , HTTP , FTP servers. In the latter case <code class="literal">virt-install</code> will fetch the minimal files necessary to kick off the installation process, allowing the guest to fetch the rest of the OS distribution as needed. PXE booting, and importing an existing disk image (thus skipping the install phase) are also supported.</p><p>To see more details about virt-install options, please visit <a class="link" href="https://linux.die.net/man/1/virt-install" target="_blank">https://linux.die.net/man/1/virt-install</a>
To see more details about virt-manager and the graphical interface, please visit <a class="link" href="https://virt-manager.org/" target="_blank">https://virt-manager.org/</a></p></section></section><section class="sect2" id="id-image-based-process-step-by-step-2" data-id-title="Image-based process step by step"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">1.4.2 </span><span class="title-name">Image-based process step by step</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-image-based-process-step-by-step-2">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>We have to create the image based and prepare the image with ignition and combustion files.
Basically we will use the following documents as reference to create the image changing the base SLEMicro image to be downloaded (<span class="strong"><strong>in this case will be SLE Micro x86_64</strong></span>):</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Download the raw image file from the SUSE website at <a class="link" href="https://www.suse.com/download/sle-micro/" target="_blank">https://www.suse.com/download/sle-micro/</a></p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Select AMD64/Intel 64 architecture</p></li><li class="listitem"><p>Look for the raw file (I.e.- <code class="literal">SLE-Micro.x86_64-5.4.0-Default-GM.raw.xz</code>)</p></li></ul></div></li></ul></div><div id="id-1.3.3.5.3.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><p>You need to have a valid user on the SUSE site to be able to download the file.</p></div><p>If you are trying to download to a remote server, you can use scp to copy that file to the server.</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Access to <a class="link" href="https://scc.suse.com/" target="_blank">SCC.suse.com</a> to generate a registration code</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Search for <code class="literal">SUSE Linux Enterprise Micro</code> via the <code class="literal">Products</code> menu, select the arch/version then copy and manually activate the registration code</p></li></ul></div></li><li class="listitem"><p>Butane, qemu-img and cdrtools installed (using zypper for example)</p></li></ul></div><div class="verbatim-wrap highlight bash"><pre class="screen">  sudo zypper install butane qemu-tools xz mkisofs</pre></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Unzip the file</p></li></ul></div><div class="verbatim-wrap highlight bash"><pre class="screen">  xz -d SLE-Micro.x86_64-5.4.0-Default-GM.raw.xz</pre></div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Resize the image file. In this example, to 30G</p></li></ul></div><div class="verbatim-wrap highlight bash"><pre class="screen"> qemu-img resize -f raw ~/PATH-TO-FILE/SLE-Micro.x86_64-5.4.0-Default-GM.raw 30G &gt; /dev/null</pre></div><section class="sect3" id="id-convert-the-raw-image-to-qcow2" data-id-title="Convert the raw image to qcow2"><div class="titlepage"><div><div><div class="title-container"><h4 class="title"><span class="title-number-name"><span class="title-number">1.4.2.1 </span><span class="title-name">Convert the raw image to qcow2</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-convert-the-raw-image-to-qcow2">#</a></h4><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><div class="verbatim-wrap highlight bash"><pre class="screen">qemu-img convert -O qcow2 SLE-Micro.x86_64-5.4.0-Default-GM.raw slemicro</pre></div></section><section class="sect3" id="id-ignition-combustion-files-2" data-id-title="Ignition Combustion files"><div class="titlepage"><div><div><div class="title-container"><h4 class="title"><span class="title-number-name"><span class="title-number">1.4.2.2 </span><span class="title-name">Ignition &amp; Combustion files</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-ignition-combustion-files-2">#</a></h4><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>To automate the installation, we will leverage Butane, Ignition and
Combustion as explained before:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Create a temporary folder to store the assets</p><div class="verbatim-wrap highlight bash"><pre class="screen">TMPDIR=$(mktemp -d)</pre></div></li><li class="listitem"><p>Create the required folders for ignition and combustion</p><div class="verbatim-wrap highlight bash"><pre class="screen">mkdir -p ${TMPDIR}/{combustion,ignition}</pre></div></li><li class="listitem"><p>Create a <code class="literal">config.fcc</code> butane config file as required. See the
following example to set a <code class="literal">root</code> password for the root user, and to
configure the hostname to be "slemicro"'</p><div class="verbatim-wrap highlight yaml"><pre class="screen">cat &lt;&lt; 'EOF' &gt; ${TMPDIR}/config.fcc
variant: fcos
version: 1.4.0
storage:
  files:
    - path: /etc/hostname
      mode: 0644
      overwrite: true
      contents:
        inline: "slemicro"
passwd:
  users:
   - name: root
     password_hash: "$y$j9T$/t4THH10B7esLiIVBROsE.$G1lyxfy/MoFVOrfXSnWAUq70Tf3mjfZBIe18koGOuXB"
EOF</pre></div></li><li class="listitem"><p>Create a script combustion file as required. See the following
example to register the SLE Micro instance to SUSE’s SCC (use your
own email/regcode) and to create a <code class="literal">/etc/issue.d/combustion</code> file</p><div class="verbatim-wrap highlight bash"><pre class="screen">cat &lt;&lt; EOF &gt; ${TMPDIR}/combustion/script
#!/bin/bash
# combustion: network

# Redirect output to the console
exec &gt; &gt;(exec tee -a /dev/tty0) 2&gt;&amp;1

# Set hostname at combustion phase for SUSEConnect
hostname slemicro

# Registration
if ! which SUSEConnect &gt; /dev/null 2&gt;&amp;1; then
    zypper --non-interactive install suseconnect-ng
fi

SUSEConnect --email foobar@suse.com --url https://scc.suse.com --regcode YOURCODE

# Leave a marker
echo "Configured with combustion" &gt; /etc/issue.d/combustion
EOF</pre></div></li><li class="listitem"><p>Convert the butane config to ignition</p><div class="verbatim-wrap highlight bash"><pre class="screen">butane -p -o ${TMPDIR}/ignition/config.ign ${TMPDIR}/config.fcc</pre></div></li><li class="listitem"><p>Create an ISO file. It is requried for both ignition and combustion
to work that the ISO is labeled as <code class="literal">ignition</code> (hence the -V
parameter)</p><div class="verbatim-wrap highlight bash"><pre class="screen">mkisofs -full-iso9660-filenames -o ignition-and-combustion.iso -V ignition ${TMPDIR}</pre></div></li><li class="listitem"><p><span class="strong"><strong>Optional:</strong></span> Remove the temporary folder</p><div class="verbatim-wrap highlight bash"><pre class="screen">rm -rf ${TMPDIR}</pre></div></li></ul></div></section><section class="sect3" id="id-create-the-vm" data-id-title="Create the VM"><div class="titlepage"><div><div><div class="title-container"><h4 class="title"><span class="title-number-name"><span class="title-number">1.4.2.3 </span><span class="title-name">Create the VM</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-create-the-vm">#</a></h4><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><div class="verbatim-wrap highlight bash"><pre class="screen">virt-install --name MyVM --memory 4096 --vcpus 4 --disk ./slemicro \
 --import --cdrom ./ignition-and-combustion.iso --network default \
 --osinfo detect=on,name=sle-unknown</pre></div><div id="id-1.3.3.5.3.14.3" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Pass the <code class="literal">--noautoconsole</code> flag in case your console hangs on the installation, this will allow you to run other commands without CTRL-C interrupt</p></li><li class="listitem"><p>Pass the <code class="literal">--debug</code> flag if you run into issues</p></li><li class="listitem"><p>If you run into an issue and you need to restart, or if you get an error saying that MyVM is already running, run this command:</p></li></ul></div><div class="verbatim-wrap highlight bash"><pre class="screen"> virsh destroy MyVM ; virsh undefine MyVM</pre></div><p>After a couple of seconds, the VM will boot up and will configure itself
using the ignition and combustion scripts, including registering itself
to SCC</p><div class="verbatim-wrap"><pre class="screen">virsh list
 Id   Nombre          State
----------------------------------
 14   MyVM          running</pre></div></div></section><section class="sect3" id="id-access-to-the-vm" data-id-title="Access to the vm"><div class="titlepage"><div><div><div class="title-container"><h4 class="title"><span class="title-number-name"><span class="title-number">1.4.2.4 </span><span class="title-name">Access to the vm</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-access-to-the-vm">#</a></h4><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>You can access to the VM using virsh console:</p><div class="verbatim-wrap"><pre class="screen">virsh console MyVM

Connected to domain MyVM</pre></div><p>or using ssh directly and the user set in the ignition file (in this case root)</p><div class="verbatim-wrap"><pre class="screen">virsh domifaddr MyVM
 Nombre     MAC address          Protocol     Address
-------------------------------------------------------------------------------
 vnet14     52:54:00:f0:be:e5    ipv4         192.168.122.221/24

ssh root@192.168.122.221</pre></div></section><section class="sect3" id="id-delete-the-vm" data-id-title="Delete the VM"><div class="titlepage"><div><div><div class="title-container"><h4 class="title"><span class="title-number-name"><span class="title-number">1.4.2.5 </span><span class="title-name">Delete the VM</span></span> <a title="Permalink" class="permalink" href="id-demolab-setups.html#id-delete-the-vm">#</a></h4><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><div class="verbatim-wrap highlight bash"><pre class="screen">virsh destroy MyVM ; virsh undefine MyVM</pre></div></section></section></section></section><nav class="bottom-pagination"><div><a class="pagination-link prev" href="id-quickstarts.html"><span class="pagination-relation">Previous</span><span class="pagination-label"><span class="title-number">Part I </span>Quickstarts</span></a> </div><div><a class="pagination-link next" href="id-standalone-clusters-with-edge-image-builder.html"><span class="pagination-relation">Next</span><span class="pagination-label"><span class="title-number">Chapter 2 </span>Standalone Clusters with Edge Image Builder</span></a> </div></nav></article><aside id="_side-toc-page" class="side-toc"><div class="side-title">On this page</div><div class="toc"><ul><li><span class="section"><a href="id-demolab-setups.html#id-elemental-on-osx-on-apple-silicon-utm"><span class="title-number">1.1 </span><span class="title-name">Elemental on OSX on Apple Silicon (UTM)</span></a></span></li><li><span class="section"><a href="id-demolab-setups.html#id-k3s-on-sle-micro"><span class="title-number">1.2 </span><span class="title-name">K3s on SLE Micro</span></a></span></li><li><span class="section"><a href="id-demolab-setups.html#id-sle-micro-on-osx-on-apple-silicon-utm"><span class="title-number">1.3 </span><span class="title-name">SLE Micro on OSX on Apple Silicon (UTM)</span></a></span></li><li><span class="section"><a href="id-demolab-setups.html#id-sle-micro-on-x86_64-on-libvirt-virt-install"><span class="title-number">1.4 </span><span class="title-name">SLE Micro on X86_64 on libvirt (virt-install)</span></a></span></li></ul></div><div class="side-title">Share this page</div><ul class="share"><li><a id="_share-fb" href="#" title="Facebook"> </a></li><li><a id="_share-in" href="#" title="LinkedIn"> </a></li><li><a id="_share-tw" href="#" title="Twitter/X"> </a></li><li><a id="_share-mail" href="#" title="E-Mail"> </a></li><li><a id="_print-button" href="#" title="Print this page"> </a></li></ul> </aside></main><footer id="_footer"><div class="growth-inhibitor"><div class="copy"><span class="copy__rights">© SUSE
                 2024</span></div></div></footer></body></html>