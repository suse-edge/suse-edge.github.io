<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><title>SUSE Edge Documentation | Edge Virtualization</title><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes"/><link rel="stylesheet" type="text/css" href="static/css/style.css"/>
<link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"/><link rel="schema.DCTERMS" href="http://purl.org/dc/terms/"/>
<meta name="title" content="Edge Virtualization"/>
<meta name="description" content="This section describes how you can use Edge Virtualization to run virtual machines on your edge nodes. Edge Virtualization is designed for lightweigh…"/>
<meta name="book-title" content="SUSE Edge Documentation"/>
<meta name="chapter-title" content="Chapter 21. Edge Virtualization"/>
<meta name="tracker-url" content="https://github.com/suse-edge/suse-edge.github.io/issues/new"/>
<meta name="tracker-type" content="gh"/>
<meta name="publisher" content="SUSE"/><meta property="og:title" content="Edge Virtualization"/>
<meta property="og:description" content="This section describes how you can use Edge Virtualization …"/>
<meta property="og:type" content="article"/>
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Edge Virtualization"/>
<meta name="twitter:description" content="This section describes how you can use Edge Virtualization …"/>
<script type="application/ld+json">{
    "@context": "http://schema.org",
    "@type": ["TechArticle"],
    "image": "https://www.suse.com/assets/img/suse-white-logo-green.svg",
    
     "isPartOf": {
      "@type": "CreativeWorkSeries",
      "name": "Products &amp; Solutions"
    },
    

    "headline": "Edge Virtualization",
  
    "description": "Edge Virtualization",
      
    "author": [
      {
        "@type": "Corporation",
        "name": "SUSE Product &amp; Solution Documentation Team",
        "url": "https://www.suse.com/assets/img/suse-white-logo-green.svg"
      }
    ],
      

    "about": [
      
    ],
  
    "sameAs": [
          "https://www.facebook.com/SUSEWorldwide/about",
          "https://www.youtube.com/channel/UCHTfqIzPKz4f_dri36lAQGA",
          "https://twitter.com/SUSE",
          "https://www.linkedin.com/company/suse"
    ],
    "publisher": {
      "@type": "Corporation",
      "name": "SUSE",
      "url": "https://documentation.suse.com",
      "logo": {
        "@type": "ImageObject",
        "url": "https://www.suse.com/assets/img/suse-white-logo-green.svg"
      }
    }
  }</script>
<link rel="prev" href="components-eco.html" title="Chapter 20. Endpoint Copier Operator"/><link rel="next" href="components-system-upgrade-controller.html" title="Chapter 22. System Upgrade Controller"/><script type="text/javascript">

if ( window.location.protocol.toLowerCase() != 'file:' ) {
  document.write('<link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css"></link>');
};

</script><noscript><link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css"/></noscript><script src="static/js/script-purejs.js" type="text/javascript"> </script><script src="static/js/highlight.min.js" type="text/javascript"> </script><script>

$(document).ready(function() {
  $('.verbatim-wrap.highlight').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});
hljs.configure({
  useBR: false
});

</script></head><body class="wide offline js-off"><div class="bypass-block"><a href="#_content">Jump to content</a><a href="#_bottom-pagination">Jump to page navigation: previous page [access key p]/next page [access key n]</a></div><header id="_mainnav"><div class="growth-inhibitor"><img src="static/images/logo.svg" alt="Logo" class="logo"/></div></header><div class="crumbs"><div class="growth-inhibitor"><a class="crumb" href="index.html">SUSE Edge Documentation</a><span> / </span><a class="crumb" href="id-components.html">Components</a><span> / </span><a class="crumb" href="components-kubevirt.html">Edge Virtualization</a></div></div><main id="_content"><nav id="_side-toc-overall" class="side-toc"><div class="side-title">SUSE Edge Documentation</div><ol><li><a href="suse-edge-documentation.html" class=" "><span class="title-number"> </span><span class="title-name">SUSE Edge 3.4 Documentation</span></a></li><li><a href="id-quick-starts.html" class="has-children "><span class="title-number">I </span><span class="title-name">Quick Starts</span></a><ol><li><a href="quickstart-metal3.html" class=" "><span class="title-number">1 </span><span class="title-name">BMC automated deployments with Metal<sup>3</sup></span></a></li><li><a href="quickstart-elemental.html" class=" "><span class="title-number">2 </span><span class="title-name">Remote host onboarding with Elemental</span></a></li><li><a href="quickstart-eib.html" class=" "><span class="title-number">3 </span><span class="title-name">Standalone clusters with Edge Image Builder</span></a></li><li><a href="quickstart-suma.html" class=" "><span class="title-number">4 </span><span class="title-name">SUSE Multi-Linux Manager</span></a></li></ol></li><li class="active"><a href="id-components.html" class="has-children you-are-here"><span class="title-number">II </span><span class="title-name">Components</span></a><ol><li><a href="components-rancher.html" class=" "><span class="title-number">5 </span><span class="title-name">Rancher</span></a></li><li><a href="components-rancher-dashboard-extensions.html" class=" "><span class="title-number">6 </span><span class="title-name">Rancher Dashboard Extensions</span></a></li><li><a href="components-rancher-turtles.html" class=" "><span class="title-number">7 </span><span class="title-name">Rancher Turtles</span></a></li><li><a href="components-fleet.html" class=" "><span class="title-number">8 </span><span class="title-name">Fleet</span></a></li><li><a href="components-slmicro.html" class=" "><span class="title-number">9 </span><span class="title-name">SUSE Linux Micro</span></a></li><li><a href="components-metal3.html" class=" "><span class="title-number">10 </span><span class="title-name">Metal<sup>3</sup></span></a></li><li><a href="components-eib.html" class=" "><span class="title-number">11 </span><span class="title-name">Edge Image Builder</span></a></li><li><a href="components-nmc.html" class=" "><span class="title-number">12 </span><span class="title-name">Edge Networking</span></a></li><li><a href="components-elemental.html" class=" "><span class="title-number">13 </span><span class="title-name">Elemental</span></a></li><li><a href="components-akri.html" class=" "><span class="title-number">14 </span><span class="title-name">Akri</span></a></li><li><a href="components-k3s.html" class=" "><span class="title-number">15 </span><span class="title-name">K3s</span></a></li><li><a href="components-rke2.html" class=" "><span class="title-number">16 </span><span class="title-name">RKE2</span></a></li><li><a href="components-suse-storage.html" class=" "><span class="title-number">17 </span><span class="title-name">SUSE Storage</span></a></li><li><a href="components-suse-security.html" class=" "><span class="title-number">18 </span><span class="title-name">SUSE Security</span></a></li><li><a href="components-metallb.html" class=" "><span class="title-number">19 </span><span class="title-name">MetalLB</span></a></li><li><a href="components-eco.html" class=" "><span class="title-number">20 </span><span class="title-name">Endpoint Copier Operator</span></a></li><li><a href="components-kubevirt.html" class=" you-are-here"><span class="title-number">21 </span><span class="title-name">Edge Virtualization</span></a></li><li><a href="components-system-upgrade-controller.html" class=" "><span class="title-number">22 </span><span class="title-name">System Upgrade Controller</span></a></li><li><a href="components-upgrade-controller.html" class=" "><span class="title-number">23 </span><span class="title-name">Upgrade Controller</span></a></li><li><a href="components-suma.html" class=" "><span class="title-number">24 </span><span class="title-name">SUSE Multi-Linux Manager</span></a></li></ol></li><li><a href="id-how-to-guides.html" class="has-children "><span class="title-number">III </span><span class="title-name">How-To Guides</span></a><ol><li><a href="guides-metallb-k3s.html" class=" "><span class="title-number">25 </span><span class="title-name">MetalLB on K3s (using Layer 2 Mode)</span></a></li><li><a href="guides-metallb-k3s-l3.html" class=" "><span class="title-number">26 </span><span class="title-name">MetalLB on K3s (using Layer 3 Mode)</span></a></li><li><a href="guides-metallb-kubernetes.html" class=" "><span class="title-number">27 </span><span class="title-name">MetalLB in front of the Kubernetes API server</span></a></li><li><a href="id-air-gapped-deployments-with-edge-image-builder.html" class=" "><span class="title-number">28 </span><span class="title-name">Air-gapped deployments with Edge Image Builder</span></a></li><li><a href="guides-kiwi-builder-images.html" class=" "><span class="title-number">29 </span><span class="title-name">Building Updated SUSE Linux Micro Images with Kiwi</span></a></li><li><a href="guides-clusterclass-example.html" class=" "><span class="title-number">30 </span><span class="title-name">Using clusterclass to deploy downstream clusters</span></a></li></ol></li><li><a href="tips-and-tricks.html" class="has-children "><span class="title-number">IV </span><span class="title-name">Tips and Tricks</span></a><ol><li><a href="tips-edge-image-builder.html" class=" "><span class="title-number">31 </span><span class="title-name">Edge Image Builder</span></a></li><li><a href="tips-elemental.html" class=" "><span class="title-number">32 </span><span class="title-name">Elemental</span></a></li></ol></li><li><a href="id-third-party-integration.html" class="has-children "><span class="title-number">V </span><span class="title-name">Third-Party Integration</span></a><ol><li><a href="integrations-nats.html" class=" "><span class="title-number">33 </span><span class="title-name">NATS</span></a></li><li><a href="id-nvidia-gpus-on-suse-linux-micro.html" class=" "><span class="title-number">34 </span><span class="title-name">NVIDIA GPUs on SUSE Linux Micro</span></a></li></ol></li><li><a href="day-2-operations.html" class="has-children "><span class="title-number">VI </span><span class="title-name">Day 2 Operations</span></a><ol><li><a href="day2-migration.html" class=" "><span class="title-number">35 </span><span class="title-name">Edge 3.3 migration</span></a></li><li><a href="day2-mgmt-cluster.html" class=" "><span class="title-number">36 </span><span class="title-name">Management Cluster</span></a></li><li><a href="day2-downstream-clusters.html" class=" "><span class="title-number">37 </span><span class="title-name">Downstream clusters</span></a></li></ol></li><li><a href="id-suse-telco-cloud-documentation.html" class="has-children "><span class="title-number">VII </span><span class="title-name">SUSE Telco Cloud Documentation</span></a><ol><li><a href="atip.html" class=" "><span class="title-number">38 </span><span class="title-name">SUSE Telco Cloud</span></a></li><li><a href="atip-architecture.html" class=" "><span class="title-number">39 </span><span class="title-name">Concept &amp; Architecture</span></a></li><li><a href="atip-requirements.html" class=" "><span class="title-number">40 </span><span class="title-name">Requirements &amp; Assumptions</span></a></li><li><a href="atip-management-cluster.html" class=" "><span class="title-number">41 </span><span class="title-name">Setting up the management cluster</span></a></li><li><a href="atip-features.html" class=" "><span class="title-number">42 </span><span class="title-name">Telco features configuration</span></a></li><li><a href="atip-automated-provisioning.html" class=" "><span class="title-number">43 </span><span class="title-name">Fully automated directed network provisioning</span></a></li><li><a href="atip-lifecycle.html" class=" "><span class="title-number">44 </span><span class="title-name">Lifecycle actions</span></a></li></ol></li><li><a href="id-troubleshooting-3.html" class="has-children "><span class="title-number">VIII </span><span class="title-name">Troubleshooting</span></a><ol><li><a href="general-troubleshooting-principles.html" class=" "><span class="title-number">45 </span><span class="title-name">General Troubleshooting Principles</span></a></li><li><a href="troubleshooting-kiwi.html" class=" "><span class="title-number">46 </span><span class="title-name">Troubleshooting Kiwi</span></a></li><li><a href="troubleshooting-edge-image-builder.html" class=" "><span class="title-number">47 </span><span class="title-name">Troubleshooting Edge Image Builder (EIB)</span></a></li><li><a href="troubleshooting-edge-networking.html" class=" "><span class="title-number">48 </span><span class="title-name">Troubleshooting Edge Networking (NMC)</span></a></li><li><a href="troubleshooting-phone-home-scenarios.html" class=" "><span class="title-number">49 </span><span class="title-name">Troubleshooting Phone-Home scenarios</span></a></li><li><a href="troubleshooting-directed-network-provisioning.html" class=" "><span class="title-number">50 </span><span class="title-name">Troubleshooting Directed-network provisioning</span></a></li><li><a href="troubleshooting-other-components.html" class=" "><span class="title-number">51 </span><span class="title-name">Troubleshooting Other components</span></a></li><li><a href="collecting-diagnostics-for-support.html" class=" "><span class="title-number">52 </span><span class="title-name">Collecting Diagnostics for Support</span></a></li></ol></li><li><a href="id-appendix.html" class="has-children "><span class="title-number">IX </span><span class="title-name">Appendix</span></a><ol><li><a href="id-release-notes.html" class=" "><span class="title-number">53 </span><span class="title-name">Release Notes</span></a></li></ol></li> </ol> </nav><button id="_open-side-toc-overall" title="Contents"> </button><article class="documentation"><button id="_unfold-side-toc-page">On this page</button><section class="chapter" id="components-kubevirt" data-id-title="Edge Virtualization"><div class="titlepage"><div><div><div class="title-container"><h1 class="title"><span class="title-number-name"><span class="title-number">21 </span><span class="title-name">Edge Virtualization</span></span> <a title="Permalink" class="permalink" href="components-kubevirt.html#">#</a></h1><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>This section describes how you can use Edge Virtualization to run virtual machines on your edge nodes. Edge Virtualization is designed for lightweight virtualization use-cases, where it is expected that a common workflow for the deployment and management of both virtualized and containerized applications will be utilized.</p><p>SUSE Edge Virtualization supports two methods of running virtual machines:</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>Deploying the virtual machines manually via libvirt+qemu-kvm at the host level (where Kubernetes is not involved)</p></li><li class="listitem"><p>Deploying the KubeVirt operator for Kubernetes-based management of virtual machines</p></li></ol></div><p>Both options are valid, but only the second one is covered below. If you want to use the standard out-of-the box virtualization mechanisms provided by SUSE Linux Micro, a comprehensive guide can be found <a class="link" href="https://documentation.suse.com/sles/15-SP6/html/SLES-all/chap-virtualization-introduction.html" target="_blank">here</a>, and whilst it was primarily written for SUSE Linux Enterprise Server, the concepts are almost identical.</p><p>This guide initially explains how to deploy the additional virtualization components onto a system that has already been pre-deployed, but follows with a section that describes how to embed this configuration in the initial deployment via Edge Image Builder. If you do not want to run through the basics and set things up manually, skip right ahead to that section.</p><section class="sect1" id="id-kubevirt-overview" data-id-title="KubeVirt overview"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">21.1 </span><span class="title-name">KubeVirt overview</span></span> <a title="Permalink" class="permalink" href="components-kubevirt.html#id-kubevirt-overview">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>KubeVirt allows for managing Virtual Machines with Kubernetes alongside the rest of your containerized workloads. It does this by running the user space portion of the Linux virtualization stack in a container. This minimizes the requirements on the host system, allowing for easier setup and management.</p><div class="informalexample"><p>Details about KubeVirt’s architecture can be found in <a class="link" href="https://kubevirt.io/user-guide/architecture/" target="_blank">the upstream documentation.</a></p></div></section><section class="sect1" id="id-prerequisites-5" data-id-title="Prerequisites"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">21.2 </span><span class="title-name">Prerequisites</span></span> <a title="Permalink" class="permalink" href="components-kubevirt.html#id-prerequisites-5">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>If you are following this guide, we assume you have the following already available:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>At least one physical host with SUSE Linux Micro 6.1 installed, and with virtualization extensions enabled in the BIOS (see <a class="link" href="https://documentation.suse.com/sles/15-SP6/html/SLES-all/cha-virt-support.html#sec-kvm-requires-hardware" target="_blank">here</a> for details).</p></li><li class="listitem"><p>Across your nodes, a K3s/RKE2 Kubernetes cluster already deployed and with an appropriate <code class="literal">kubeconfig</code> that enables superuser access to the cluster.</p></li><li class="listitem"><p>Access to the root user — these instructions assume you are the root user, and <span class="emphasis"><em>not</em></span> escalating your privileges via <code class="literal">sudo</code>.</p></li><li class="listitem"><p>You have <a class="link" href="https://helm.sh/docs/intro/install/" target="_blank">Helm</a> available locally with an adequate network connection to be able to push configurations to your Kubernetes cluster and download the required images.</p></li></ul></div></section><section class="sect1" id="id-manual-installation-of-edge-virtualization" data-id-title="Manual installation of Edge Virtualization"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">21.3 </span><span class="title-name">Manual installation of Edge Virtualization</span></span> <a title="Permalink" class="permalink" href="components-kubevirt.html#id-manual-installation-of-edge-virtualization">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>This guide will not walk you through the deployment of Kubernetes, but it assumes that you have either installed the SUSE Edge-appropriate version of <a class="link" href="https://k3s.io/" target="_blank">K3s</a> or <a class="link" href="https://docs.rke2.io/install/quickstart" target="_blank">RKE2</a> and that you have your kubeconfig configured accordingly so that standard <code class="literal">kubectl</code> commands can be executed as the superuser. We assume your node forms a single-node cluster, although there are no significant differences expected for multi-node deployments.</p><p>SUSE Edge Virtualization is deployed via three separate Helm charts, specifically:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p><span class="strong"><strong>KubeVirt</strong></span>: The core virtualization components, that is, Kubernetes CRDs, operators and other components required for enabling Kubernetes to deploy and manage virtual machines.</p></li><li class="listitem"><p><span class="strong"><strong>KubeVirt Dashboard Extension</strong></span>: An optional Rancher UI extension that allows basic virtual machine management, for example, starting/stopping of virtual machines as well as accessing the console.</p></li><li class="listitem"><p><span class="strong"><strong>Containerized Data Importer (CDI)</strong></span>: An additional component that enables persistent-storage integration for KubeVirt, providing capabilities for virtual machines to use existing Kubernetes storage back-ends for data, but also allowing users to import or clone data volumes for virtual machines.</p></li></ul></div><p>Each of these Helm charts is versioned according to the SUSE Edge release you are currently using. For production/supported usage, employ the artifacts that can be found in the SUSE Registry.</p><p>First, ensure that your <code class="literal">kubectl</code> access is working:</p><div class="verbatim-wrap"><pre class="screen">$ kubectl get nodes</pre></div><p>This should show something similar to the following:</p><div class="verbatim-wrap"><pre class="screen">NAME                   STATUS   ROLES                       AGE     VERSION
node1.edge.rdo.wales   Ready    control-plane,etcd,master   4h20m   v1.30.5+rke2r1
node2.edge.rdo.wales   Ready    control-plane,etcd,master   4h15m   v1.30.5+rke2r1
node3.edge.rdo.wales   Ready    control-plane,etcd,master   4h15m   v1.30.5+rke2r1</pre></div><p>Now you can proceed to install the <span class="strong"><strong>KubeVirt</strong></span> and <span class="strong"><strong>Containerized Data Importer (CDI)</strong></span> Helm charts:</p><div class="verbatim-wrap"><pre class="screen">$ helm install kubevirt oci://registry.suse.com/edge/charts/kubevirt --namespace kubevirt-system --create-namespace
$ helm install cdi oci://registry.suse.com/edge/charts/cdi --namespace cdi-system --create-namespace</pre></div><p>In a few minutes, you should have all KubeVirt and CDI components deployed. You can validate this by checking all the deployed resources in the <code class="literal">kubevirt-system</code> and <code class="literal">cdi-system</code> namespace.</p><p>Verify KubeVirt resources:</p><div class="verbatim-wrap"><pre class="screen">$ kubectl get all -n kubevirt-system</pre></div><p>This should show something similar to the following:</p><div class="verbatim-wrap"><pre class="screen">NAME                                   READY   STATUS    RESTARTS      AGE
pod/virt-operator-5fbcf48d58-p7xpm     1/1     Running   0             2m24s
pod/virt-operator-5fbcf48d58-wnf6s     1/1     Running   0             2m24s
pod/virt-handler-t594x                 1/1     Running   0             93s
pod/virt-controller-5f84c69884-cwjvd   1/1     Running   1 (64s ago)   93s
pod/virt-controller-5f84c69884-xxw6q   1/1     Running   1 (64s ago)   93s
pod/virt-api-7dfc54cf95-v8kcl          1/1     Running   1 (59s ago)   118s

NAME                                  TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
service/kubevirt-prometheus-metrics   ClusterIP   None            &lt;none&gt;        443/TCP   2m1s
service/virt-api                      ClusterIP   10.43.56.140    &lt;none&gt;        443/TCP   2m1s
service/kubevirt-operator-webhook     ClusterIP   10.43.201.121   &lt;none&gt;        443/TCP   2m1s
service/virt-exportproxy              ClusterIP   10.43.83.23     &lt;none&gt;        443/TCP   2m1s

NAME                          DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
daemonset.apps/virt-handler   1         1         1       1            1           kubernetes.io/os=linux   93s

NAME                              READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/virt-operator     2/2     2            2           2m24s
deployment.apps/virt-controller   2/2     2            2           93s
deployment.apps/virt-api          1/1     1            1           118s

NAME                                         DESIRED   CURRENT   READY   AGE
replicaset.apps/virt-operator-5fbcf48d58     2         2         2       2m24s
replicaset.apps/virt-controller-5f84c69884   2         2         2       93s
replicaset.apps/virt-api-7dfc54cf95          1         1         1       118s

NAME                            AGE     PHASE
kubevirt.kubevirt.io/kubevirt   2m24s   Deployed</pre></div><p>Verify CDI resources:</p><div class="verbatim-wrap"><pre class="screen">$ kubectl get all -n cdi-system</pre></div><p>This should show something similar to the following:</p><div class="verbatim-wrap"><pre class="screen">NAME                                   READY   STATUS    RESTARTS   AGE
pod/cdi-operator-55c74f4b86-692xb      1/1     Running   0          2m24s
pod/cdi-apiserver-db465b888-62lvr      1/1     Running   0          2m21s
pod/cdi-deployment-56c7d74995-mgkfn    1/1     Running   0          2m21s
pod/cdi-uploadproxy-7d7b94b968-6kxc2   1/1     Running   0          2m22s

NAME                             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE
service/cdi-uploadproxy          ClusterIP   10.43.117.7    &lt;none&gt;        443/TCP    2m22s
service/cdi-api                  ClusterIP   10.43.20.101   &lt;none&gt;        443/TCP    2m22s
service/cdi-prometheus-metrics   ClusterIP   10.43.39.153   &lt;none&gt;        8080/TCP   2m21s

NAME                              READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/cdi-operator      1/1     1            1           2m24s
deployment.apps/cdi-apiserver     1/1     1            1           2m22s
deployment.apps/cdi-deployment    1/1     1            1           2m21s
deployment.apps/cdi-uploadproxy   1/1     1            1           2m22s

NAME                                         DESIRED   CURRENT   READY   AGE
replicaset.apps/cdi-operator-55c74f4b86      1         1         1       2m24s
replicaset.apps/cdi-apiserver-db465b888      1         1         1       2m21s
replicaset.apps/cdi-deployment-56c7d74995    1         1         1       2m21s
replicaset.apps/cdi-uploadproxy-7d7b94b968   1         1         1       2m22s</pre></div><p>To verify that the <code class="literal">VirtualMachine</code> custom resource definitions (CRDs) are deployed, you can validate with:</p><div class="verbatim-wrap"><pre class="screen">$ kubectl explain virtualmachine</pre></div><p>This should print out the definition of the <code class="literal">VirtualMachine</code> object, which should print as follows:</p><div class="verbatim-wrap"><pre class="screen">GROUP:      kubevirt.io
KIND:       VirtualMachine
VERSION:    v1

DESCRIPTION:
    VirtualMachine handles the VirtualMachines that are not running or are in a
    stopped state The VirtualMachine contains the template to create the
    VirtualMachineInstance. It also mirrors the running state of the created
    VirtualMachineInstance in its status.
(snip)</pre></div></section><section class="sect1" id="id-deploying-virtual-machines" data-id-title="Deploying virtual machines"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">21.4 </span><span class="title-name">Deploying virtual machines</span></span> <a title="Permalink" class="permalink" href="components-kubevirt.html#id-deploying-virtual-machines">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>Now that KubeVirt and CDI are deployed, let us define a simple virtual machine based on <a class="link" href="https://get.opensuse.org/tumbleweed/" target="_blank">openSUSE Tumbleweed</a>. This virtual machine has the most simple of configurations, using standard "pod networking" for a networking configuration identical to any other pod. It also employs non-persistent storage, ensuring the storage is ephemeral, just like in any container that does not have a <a class="link" href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/" target="_blank">PVC</a>.</p><div class="verbatim-wrap"><pre class="screen">$ kubectl apply -f - &lt;&lt;EOF
apiVersion: kubevirt.io/v1
kind: VirtualMachine
metadata:
  name: tumbleweed
  namespace: default
spec:
  runStrategy: Always
  template:
    spec:
      domain:
        devices: {}
        machine:
          type: q35
        memory:
          guest: 2Gi
        resources: {}
      volumes:
      - containerDisk:
          image: registry.opensuse.org/home/roxenham/tumbleweed-container-disk/containerfile/cloud-image:latest
        name: tumbleweed-containerdisk-0
      - cloudInitNoCloud:
          userDataBase64: I2Nsb3VkLWNvbmZpZwpkaXNhYmxlX3Jvb3Q6IGZhbHNlCnNzaF9wd2F1dGg6IFRydWUKdXNlcnM6CiAgLSBkZWZhdWx0CiAgLSBuYW1lOiBzdXNlCiAgICBncm91cHM6IHN1ZG8KICAgIHNoZWxsOiAvYmluL2Jhc2gKICAgIHN1ZG86ICBBTEw9KEFMTCkgTk9QQVNTV0Q6QUxMCiAgICBsb2NrX3Bhc3N3ZDogRmFsc2UKICAgIHBsYWluX3RleHRfcGFzc3dkOiAnc3VzZScK
        name: cloudinitdisk
EOF</pre></div><p>This should print that a <code class="literal">VirtualMachine</code> was created:</p><div class="verbatim-wrap"><pre class="screen">virtualmachine.kubevirt.io/tumbleweed created</pre></div><p>This <code class="literal">VirtualMachine</code> definition is minimal, specifying little about the configuration. It simply outlines that it is a machine type "<a class="link" href="https://wiki.qemu.org/Features/Q35" target="_blank">q35</a>" with 2 GB of memory that uses a disk image based on an ephemeral <code class="literal"><a class="link" href="https://kubevirt.io/user-guide/virtual_machines/disks_and_volumes/#containerdisk" target="_blank">containerDisk</a></code> (that is, a disk image that is stored in a container image from a remote image repository), and specifies a base64 encoded cloudInit disk, which we only use for user creation and password enforcement at boot time (use <code class="literal">base64 -d</code> to decode it).</p><div class="blockquote"><blockquote class="blockquote"><div id="id-1.4.19.10.7.1" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><p>This virtual machine image is only for testing. The image is not officially supported and is only meant as a documentation example.</p></div></blockquote></div><p>This machine takes a few minutes to boot as it needs to download the openSUSE Tumbleweed disk image, but once it has done so, you can view further details about the virtual machine by checking the virtual machine information:</p><div class="verbatim-wrap"><pre class="screen">$ kubectl get vmi</pre></div><p>This should print the node that the virtual machine was started on, and the IP address of the virtual machine. Remember, since it uses pod networking, the reported IP address will be just like any other pod, and routable as such:</p><div class="verbatim-wrap"><pre class="screen">NAME         AGE     PHASE     IP           NODENAME               READY
tumbleweed   4m24s   Running   10.42.2.98   node3.edge.rdo.wales   True</pre></div><p>When running these commands on the Kubernetes cluster nodes themselves, with a CNI that routes traffic directly to pods (for example, Cilium), you should be able to <code class="literal">ssh</code> directly to the machine itself. Substitute the following IP address with the one that was assigned to your virtual machine:</p><div class="verbatim-wrap"><pre class="screen">$ ssh suse@10.42.2.98
(password is "suse")</pre></div><p>Once you are in this virtual machine, you can play around, but remember that it is limited in terms of resources, and only has 1 GB disk space. When you are finished, <code class="literal">Ctrl-D</code> or <code class="literal">exit</code> to disconnect from the SSH session.</p><p>The virtual machine process is still wrapped in a standard Kubernetes pod. The <code class="literal">VirtualMachine</code> CRD is a representation of the desired virtual machine, but the process in which the virtual machine is actually started is via the <code class="literal"><a class="link" href="https://github.com/kubevirt/kubevirt/blob/main/docs/components.md#virt-launcher" target="_blank">virt-launcher</a></code> pod, a standard Kubernetes pod, just like any other application. For every virtual machine started, you can see there is a <code class="literal">virt-launcher</code> pod:</p><div class="verbatim-wrap"><pre class="screen">$ kubectl get pods</pre></div><p>This should then show the one <code class="literal">virt-launcher</code> pod for the Tumbleweed machine that we have defined:</p><div class="verbatim-wrap"><pre class="screen">NAME                             READY   STATUS    RESTARTS   AGE
virt-launcher-tumbleweed-8gcn4   3/3     Running   0          10m</pre></div><p>If we take a look into this <code class="literal">virt-launcher</code> pod, you see it is executing <code class="literal">libvirt</code> and <code class="literal">qemu-kvm</code> processes. We can enter the pod itself and have a look under the covers, noting that you need to adapt the following command for your pod name:</p><div class="verbatim-wrap"><pre class="screen">$ kubectl exec -it virt-launcher-tumbleweed-8gcn4 -- bash</pre></div><p>Once you are in the pod, try running <code class="literal">virsh</code> commands along with looking at the processes. You will see the <code class="literal">qemu-system-x86_64</code> binary running, along with certain processes for monitoring the virtual machine. You will also see the location of the disk image and how the networking is plugged (as a tap device):</p><div class="verbatim-wrap"><pre class="screen">qemu@tumbleweed:/&gt; ps ax
  PID TTY      STAT   TIME COMMAND
    1 ?        Ssl    0:00 /usr/bin/virt-launcher-monitor --qemu-timeout 269s --name tumbleweed --uid b9655c11-38f7-4fa8-8f5d-bfe987dab42c --namespace default --kubevirt-share-dir /var/run/kubevirt --ephemeral-disk-dir /var/run/kubevirt-ephemeral-disks --container-disk-dir /var/run/kube
   12 ?        Sl     0:01 /usr/bin/virt-launcher --qemu-timeout 269s --name tumbleweed --uid b9655c11-38f7-4fa8-8f5d-bfe987dab42c --namespace default --kubevirt-share-dir /var/run/kubevirt --ephemeral-disk-dir /var/run/kubevirt-ephemeral-disks --container-disk-dir /var/run/kubevirt/con
   24 ?        Sl     0:00 /usr/sbin/virtlogd -f /etc/libvirt/virtlogd.conf
   25 ?        Sl     0:01 /usr/sbin/virtqemud -f /var/run/libvirt/virtqemud.conf
   83 ?        Sl     0:31 /usr/bin/qemu-system-x86_64 -name guest=default_tumbleweed,debug-threads=on -S -object {"qom-type":"secret","id":"masterKey0","format":"raw","file":"/var/run/kubevirt-private/libvirt/qemu/lib/domain-1-default_tumbleweed/master-key.aes"} -machine pc-q35-7.1,usb
  286 pts/0    Ss     0:00 bash
  320 pts/0    R+     0:00 ps ax

qemu@tumbleweed:/&gt; virsh list --all
 Id   Name                 State
------------------------------------
 1    default_tumbleweed   running

qemu@tumbleweed:/&gt; virsh domblklist 1
 Target   Source
---------------------------------------------------------------------------------------------
 sda      /var/run/kubevirt-ephemeral-disks/disk-data/tumbleweed-containerdisk-0/disk.qcow2
 sdb      /var/run/kubevirt-ephemeral-disks/cloud-init-data/default/tumbleweed/noCloud.iso

qemu@tumbleweed:/&gt; virsh domiflist 1
 Interface   Type       Source   Model                     MAC
------------------------------------------------------------------------------
 tap0        ethernet   -        virtio-non-transitional   e6:e9:1a:05:c0:92

qemu@tumbleweed:/&gt; exit
exit</pre></div><p>Finally, let us delete this virtual machine to clean up:</p><div class="verbatim-wrap"><pre class="screen">$ kubectl delete vm/tumbleweed
virtualmachine.kubevirt.io "tumbleweed" deleted</pre></div></section><section class="sect1" id="id-using-virtctl" data-id-title="Using virtctl"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">21.5 </span><span class="title-name">Using virtctl</span></span> <a title="Permalink" class="permalink" href="components-kubevirt.html#id-using-virtctl">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>Along with the standard Kubernetes CLI tooling, that is, <code class="literal">kubectl</code>, KubeVirt comes with an accompanying CLI utility that allows you to interface with your cluster in a way that bridges some gaps between the virtualization world and the world that Kubernetes was designed for. For example, the <code class="literal">virtctl</code> tool provides the capability of managing the lifecycle of virtual machines (starting, stopping, restarting, etc.), providing access to the virtual consoles, uploading virtual machine images, as well as interfacing with Kubernetes constructs such as services, without using the API or CRDs directly.</p><p>Let us download the latest stable version of the <code class="literal">virtctl</code> tool:</p><div class="verbatim-wrap"><pre class="screen">$ export VERSION=v1.5.2
$ wget https://github.com/kubevirt/kubevirt/releases/download/$VERSION/virtctl-$VERSION-linux-amd64</pre></div><p>If you are using a different architecture or a non-Linux machine, you can find other releases <a class="link" href="https://github.com/kubevirt/kubevirt/releases" target="_blank">here</a>. You need to make this executable before proceeding, and it may be useful to move it to a location within your <code class="literal">$PATH</code>:</p><div class="verbatim-wrap"><pre class="screen">$ mv virtctl-$VERSION-linux-amd64 /usr/local/bin/virtctl
$ chmod a+x /usr/local/bin/virtctl</pre></div><p>You can then use the <code class="literal">virtctl</code> command-line tool to create virtual machines. Let us replicate our previous virtual machine, noting that we are piping the output directly into <code class="literal">kubectl apply</code>:</p><div class="verbatim-wrap"><pre class="screen">$ virtctl create vm --name virtctl-example --memory=1Gi \
    --volume-containerdisk=src:registry.opensuse.org/home/roxenham/tumbleweed-container-disk/containerfile/cloud-image:latest \
    --cloud-init-user-data "I2Nsb3VkLWNvbmZpZwpkaXNhYmxlX3Jvb3Q6IGZhbHNlCnNzaF9wd2F1dGg6IFRydWUKdXNlcnM6CiAgLSBkZWZhdWx0CiAgLSBuYW1lOiBzdXNlCiAgICBncm91cHM6IHN1ZG8KICAgIHNoZWxsOiAvYmluL2Jhc2gKICAgIHN1ZG86ICBBTEw9KEFMTCkgTk9QQVNTV0Q6QUxMCiAgICBsb2NrX3Bhc3N3ZDogRmFsc2UKICAgIHBsYWluX3RleHRfcGFzc3dkOiAnc3VzZScK" | kubectl apply -f -</pre></div><p>This should then show the virtual machine running (it should start a lot quicker this time given that the container image will be cached):</p><div class="verbatim-wrap"><pre class="screen">$ kubectl get vmi
NAME              AGE   PHASE     IP           NODENAME               READY
virtctl-example   52s   Running   10.42.2.29   node3.edge.rdo.wales   True</pre></div><p>Now we can use <code class="literal">virtctl</code> to connect directly to the virtual machine:</p><div class="verbatim-wrap"><pre class="screen">$ virtctl ssh suse@virtctl-example
(password is "suse" - Ctrl-D to exit)</pre></div><p>There are plenty of other commands that can be used by <code class="literal">virtctl</code>. For example, <code class="literal">virtctl console</code> can give you access to the serial console if networking is not working, and you can use <code class="literal">virtctl  guestosinfo</code> to get comprehensive OS information, subject to the guest having the <code class="literal">qemu-guest-agent</code> installed and running.</p><p>Finally, let us pause and resume the virtual machine:</p><div class="verbatim-wrap"><pre class="screen">$ virtctl pause vm virtctl-example
VMI virtctl-example was scheduled to pause</pre></div><p>You find that the <code class="literal">VirtualMachine</code> object shows as <span class="strong"><strong>Paused</strong></span> and the <code class="literal">VirtualMachineInstance</code> object shows as <span class="strong"><strong>Running</strong></span> but <span class="strong"><strong>READY=False</strong></span>:</p><div class="verbatim-wrap"><pre class="screen">$ kubectl get vm
NAME              AGE     STATUS   READY
virtctl-example   8m14s   Paused   False

$ kubectl get vmi
NAME              AGE     PHASE     IP           NODENAME               READY
virtctl-example   8m15s   Running   10.42.2.29   node3.edge.rdo.wales   False</pre></div><p>You also find that you can no longer connect to the virtual machine:</p><div class="verbatim-wrap"><pre class="screen">$ virtctl ssh suse@virtctl-example
can't access VMI virtctl-example: Operation cannot be fulfilled on virtualmachineinstance.kubevirt.io "virtctl-example": VMI is paused</pre></div><p>Let us resume the virtual machine and try again:</p><div class="verbatim-wrap"><pre class="screen">$ virtctl unpause vm virtctl-example
VMI virtctl-example was scheduled to unpause</pre></div><p>Now we should be able to re-establish a connection:</p><div class="verbatim-wrap"><pre class="screen">$ virtctl ssh suse@virtctl-example
suse@vmi/virtctl-example.default's password:
suse@virtctl-example:~&gt; exit
logout</pre></div><p>Finally, let us remove the virtual machine:</p><div class="verbatim-wrap"><pre class="screen">$ kubectl delete vm/virtctl-example
virtualmachine.kubevirt.io "virtctl-example" deleted</pre></div></section><section class="sect1" id="id-simple-ingress-networking" data-id-title="Simple ingress networking"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">21.6 </span><span class="title-name">Simple ingress networking</span></span> <a title="Permalink" class="permalink" href="components-kubevirt.html#id-simple-ingress-networking">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>In this section, we show how you can expose virtual machines as standard Kubernetes services and make them available via the Kubernetes ingress service, for example, <a class="link" href="https://docs.rke2.io/networking/networking_services#nginx-ingress-controller" target="_blank">NGINX with RKE2</a> or <a class="link" href="https://docs.k3s.io/networking/networking-services#traefik-ingress-controller" target="_blank">Traefik with K3s</a>. This document assumes that these components are already configured appropriately and that you have an appropriate DNS pointer, for example, via a wild card, to point at your Kubernetes server nodes or your ingress virtual IP for proper ingress resolution.</p><div class="blockquote"><blockquote class="blockquote"><div id="id-1.4.19.12.3.1" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><p>In SUSE Edge 3.1+, if you are using K3s in a multi-server node configuration, you might have needed to configure a MetalLB-based VIP for Ingress; this is not required for RKE2.</p></div></blockquote></div><p>In the example environment, another openSUSE Tumbleweed virtual machine is deployed, cloud-init is used to install NGINX as a simple Web server at boot time, and a simple message is configured to be returned to verify that it works as expected when a call is made. To see how this is done, simply <code class="literal">base64 -d</code> the cloud-init section in the output below.</p><p>Let us create this virtual machine now:</p><div class="verbatim-wrap"><pre class="screen">$ kubectl apply -f - &lt;&lt;EOF
apiVersion: kubevirt.io/v1
kind: VirtualMachine
metadata:
  name: ingress-example
  namespace: default
spec:
  runStrategy: Always
  template:
    metadata:
      labels:
        app: nginx
    spec:
      domain:
        devices: {}
        machine:
          type: q35
        memory:
          guest: 2Gi
        resources: {}
      volumes:
      - containerDisk:
          image: registry.opensuse.org/home/roxenham/tumbleweed-container-disk/containerfile/cloud-image:latest
        name: tumbleweed-containerdisk-0
      - cloudInitNoCloud:
          userDataBase64: I2Nsb3VkLWNvbmZpZwpkaXNhYmxlX3Jvb3Q6IGZhbHNlCnNzaF9wd2F1dGg6IFRydWUKdXNlcnM6CiAgLSBkZWZhdWx0CiAgLSBuYW1lOiBzdXNlCiAgICBncm91cHM6IHN1ZG8KICAgIHNoZWxsOiAvYmluL2Jhc2gKICAgIHN1ZG86ICBBTEw9KEFMTCkgTk9QQVNTV0Q6QUxMCiAgICBsb2NrX3Bhc3N3ZDogRmFsc2UKICAgIHBsYWluX3RleHRfcGFzc3dkOiAnc3VzZScKcnVuY21kOgogIC0genlwcGVyIGluIC15IG5naW54CiAgLSBzeXN0ZW1jdGwgZW5hYmxlIC0tbm93IG5naW54CiAgLSBlY2hvICJJdCB3b3JrcyEiID4gL3Nydi93d3cvaHRkb2NzL2luZGV4Lmh0bQo=
        name: cloudinitdisk
EOF</pre></div><p>When this virtual machine has successfully started, we can use the <code class="literal">virtctl</code> command to expose the <code class="literal">VirtualMachineInstance</code> with an external port of <code class="literal">8080</code> and a target port of <code class="literal">80</code> (where NGINX listens by default). We use the <code class="literal">virtctl</code> command here as it understands the mapping between the virtual machine object and the pod. This creates a new service for us:</p><div class="verbatim-wrap"><pre class="screen">$ virtctl expose vmi ingress-example --port=8080 --target-port=80 --name=ingress-example
Service ingress-example successfully exposed for vmi ingress-example</pre></div><p>We will then have an appropriate service automatically created:</p><div class="verbatim-wrap"><pre class="screen">$ kubectl get svc/ingress-example
NAME              TYPE           CLUSTER-IP      EXTERNAL-IP       PORT(S)                         AGE
ingress-example   ClusterIP      10.43.217.19    &lt;none&gt;            8080/TCP                        9s</pre></div><p>Next, if you then use <code class="literal">kubectl create ingress</code>, we can create an ingress object that points to this service. Adapt the URL (known as the "host" in the <a class="link" href="https://kubernetes.io/docs/reference/kubectl/generated/kubectl_create/kubectl_create_ingress/" target="_blank">ingress</a> object) here to match your DNS configuration and ensure that you point it to port <code class="literal">8080</code>:</p><div class="verbatim-wrap"><pre class="screen">$ kubectl create ingress ingress-example --rule=ingress-example.suse.local/=ingress-example:8080</pre></div><p>With DNS being configured correctly, you should be able to curl the URL immediately:</p><div class="verbatim-wrap"><pre class="screen">$ curl ingress-example.suse.local
It works!</pre></div><p>Let us clean up by removing this virtual machine and its service and ingress resources:</p><div class="verbatim-wrap"><pre class="screen">$ kubectl delete vm/ingress-example svc/ingress-example ingress/ingress-example
virtualmachine.kubevirt.io "ingress-example" deleted
service "ingress-example" deleted
ingress.networking.k8s.io "ingress-example" deleted</pre></div></section><section class="sect1" id="id-using-the-rancher-ui-extension" data-id-title="Using the Rancher UI extension"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">21.7 </span><span class="title-name">Using the Rancher UI extension</span></span> <a title="Permalink" class="permalink" href="components-kubevirt.html#id-using-the-rancher-ui-extension">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>SUSE Edge Virtualization provides a UI extension for Rancher Manager, enabling basic virtual machine management using the Rancher dashboard UI.</p><section class="sect2" id="id-installation-4" data-id-title="Installation"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">21.7.1 </span><span class="title-name">Installation</span></span> <a title="Permalink" class="permalink" href="components-kubevirt.html#id-installation-4">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>See Rancher Dashboard Extensions (<a class="xref" href="components-rancher-dashboard-extensions.html" title="Chapter 6. Rancher Dashboard Extensions">Chapter 6, <em>Rancher Dashboard Extensions</em></a>) for installation guidance.</p></section><section class="sect2" id="kubevirt-dashboard-extension-usage" data-id-title="Using KubeVirt Rancher Dashboard Extension"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">21.7.2 </span><span class="title-name">Using KubeVirt Rancher Dashboard Extension</span></span> <a title="Permalink" class="permalink" href="components-kubevirt.html#kubevirt-dashboard-extension-usage">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>The extension introduces a new <span class="strong"><strong>KubeVirt</strong></span> section to the Cluster Explorer. This section is added to any managed cluster which has KubeVirt installed.</p><p>The extension allows you to directly interact with KubeVirt Virtual Machine resources to manage Virtual Machines lifecycle.</p><section class="sect3" id="id-creating-a-virtual-machine" data-id-title="Creating a virtual machine"><div class="titlepage"><div><div><div class="title-container"><h4 class="title"><span class="title-number-name"><span class="title-number">21.7.2.1 </span><span class="title-name">Creating a virtual machine</span></span> <a title="Permalink" class="permalink" href="components-kubevirt.html#id-creating-a-virtual-machine">#</a></h4><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>Navigate to <span class="strong"><strong>Cluster Explorer</strong></span> clicking KubeVirt-enabled managed cluster in the left navigation.</p></li><li class="listitem"><p>Navigate to <span class="strong"><strong>KubeVirt &gt; Virtual Machines</strong></span> page and click <code class="literal">Create from YAML</code> in the upper right of the screen.</p></li><li class="listitem"><p>Fill in or paste a virtual machine definition and press <code class="literal">Create</code>. Use virtual machine definition from Deploying Virtual Machines section as an inspiration.</p></li></ol></div><div class="informalfigure"><div class="mediaobject"><a href="images/virtual-machines-page.png"><img src="images/virtual-machines-page.png" width="NaN" alt="virtual machines page" title="virtual machines page"/></a></div></div></section><section class="sect3" id="id-virtual-machine-actions" data-id-title="Virtual Machine Actions"><div class="titlepage"><div><div><div class="title-container"><h4 class="title"><span class="title-number-name"><span class="title-number">21.7.2.2 </span><span class="title-name">Virtual Machine Actions</span></span> <a title="Permalink" class="permalink" href="components-kubevirt.html#id-virtual-machine-actions">#</a></h4><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>You can use the action menu accessed from the <span class="strong"><strong>⋮</strong></span> drop-down list to the right of each virtual machine to perform start, stop, pause or soft reboot actions. Alternatively you can also use group actions at the top of the list by selecting virtual machines to perform the action on.</p><p>Performing the actions may have an effect on Virtual Machine Run Strategy. <a class="link" href="https://kubevirt.io/user-guide/compute/run_strategies/#virtctl" target="_blank">See the table in KubeVirt documentation</a> for more details.</p></section><section class="sect3" id="id-accessing-virtual-machine-console" data-id-title="Accessing virtual machine console"><div class="titlepage"><div><div><div class="title-container"><h4 class="title"><span class="title-number-name"><span class="title-number">21.7.2.3 </span><span class="title-name">Accessing virtual machine console</span></span> <a title="Permalink" class="permalink" href="components-kubevirt.html#id-accessing-virtual-machine-console">#</a></h4><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>The "Virtual machines" list provides a <code class="literal">Console</code> drop-down list that allows to connect to the machine using <span class="strong"><strong>VNC or Serial Console</strong></span>. This action is only available to running machines.</p><p>In some cases, it takes a short while before the console is accessible on a freshly started virtual machine.</p><div class="informalfigure"><div class="mediaobject"><a href="images/vnc-console-ui.png"><img src="images/vnc-console-ui.png" width="NaN" alt="vnc console ui" title="vnc console ui"/></a></div></div></section></section></section><section class="sect1" id="id-installing-with-edge-image-builder-4" data-id-title="Installing with Edge Image Builder"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">21.8 </span><span class="title-name">Installing with Edge Image Builder</span></span> <a title="Permalink" class="permalink" href="components-kubevirt.html#id-installing-with-edge-image-builder-4">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>SUSE Edge is using <a class="xref" href="components-eib.html" title="Chapter 11. Edge Image Builder">Chapter 11, <em>Edge Image Builder</em></a> in order to customize base SUSE Linux Micro OS images.
Follow <a class="xref" href="id-air-gapped-deployments-with-edge-image-builder.html#kubevirt-install" title="28.9. KubeVirt and CDI Installation">Section 28.9, “KubeVirt and CDI Installation”</a> for an air-gapped installation of both KubeVirt and CDI on top of Kubernetes clusters provisioned by EIB.</p></section></section><nav class="bottom-pagination"><div><a class="pagination-link prev" href="components-eco.html"><span class="pagination-relation">Previous</span><span class="pagination-label"><span class="title-number">Chapter 20 </span>Endpoint Copier Operator</span></a> </div><div><a class="pagination-link next" href="components-system-upgrade-controller.html"><span class="pagination-relation">Next</span><span class="pagination-label"><span class="title-number">Chapter 22 </span>System Upgrade Controller</span></a> </div></nav></article><aside id="_side-toc-page" class="side-toc"><div class="side-title">On this page</div><div class="toc"><ul><li><span class="section"><a href="components-kubevirt.html#id-kubevirt-overview"><span class="title-number">21.1 </span><span class="title-name">KubeVirt overview</span></a></span></li><li><span class="section"><a href="components-kubevirt.html#id-prerequisites-5"><span class="title-number">21.2 </span><span class="title-name">Prerequisites</span></a></span></li><li><span class="section"><a href="components-kubevirt.html#id-manual-installation-of-edge-virtualization"><span class="title-number">21.3 </span><span class="title-name">Manual installation of Edge Virtualization</span></a></span></li><li><span class="section"><a href="components-kubevirt.html#id-deploying-virtual-machines"><span class="title-number">21.4 </span><span class="title-name">Deploying virtual machines</span></a></span></li><li><span class="section"><a href="components-kubevirt.html#id-using-virtctl"><span class="title-number">21.5 </span><span class="title-name">Using virtctl</span></a></span></li><li><span class="section"><a href="components-kubevirt.html#id-simple-ingress-networking"><span class="title-number">21.6 </span><span class="title-name">Simple ingress networking</span></a></span></li><li><span class="section"><a href="components-kubevirt.html#id-using-the-rancher-ui-extension"><span class="title-number">21.7 </span><span class="title-name">Using the Rancher UI extension</span></a></span></li><li><span class="section"><a href="components-kubevirt.html#id-installing-with-edge-image-builder-4"><span class="title-number">21.8 </span><span class="title-name">Installing with Edge Image Builder</span></a></span></li></ul></div><div class="side-title">Share this page</div><ul class="share"><li><a id="_share-fb" href="#" title="Facebook"> </a></li><li><a id="_share-in" href="#" title="LinkedIn"> </a></li><li><a id="_share-tw" href="#" title="Twitter/X"> </a></li><li><a id="_share-mail" href="#" title="E-Mail"> </a></li><li><a id="_print-button" href="#" title="Print this page"> </a></li></ul> </aside></main><footer id="_footer"><div class="growth-inhibitor"><div class="copy"><span class="copy__rights">© SUSE
                 2025</span></div></div></footer></body></html>